{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "sns.set_theme(style=\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Putting Together a Base Dataset\n",
    "\n",
    "In this notebook we are going to create a base table on which to train a first simple model on. This dataset will contain \n",
    "- __Cell-line features__ like Gene Expression and Copy-Number-Variation information as one input and \n",
    "- __Drug Features__ as the de-Morgan fingerprints for specific drugs as another input. \n",
    "\n",
    "These features got created in the following notebooks:  \n",
    "- `02_GDSC_map_GenExpr.ipynb`\n",
    "- `03_GDSC_map_CNV.ipynb`\n",
    "- `05_DrugFeatures.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/cwoest/Documents/Academics/Data_Science_UP/master_thesis/material/GNN-material\n",
      "37700889        0 drwxr-xr-x    8 cwoest           staff                 256 May  9 16:27 ../../datasets/gdsc/my_datasets\n",
      "37938781    96424 -rw-r--r--    1 cwoest           staff            49365274 May  9 15:54 ../../datasets/gdsc/my_datasets/gdsc_base.pkl\n",
      "37704542  7461488 -rw-r--r--    1 cwoest           staff            3820277941 May  5 14:52 ../../datasets/gdsc/my_datasets/joined_gdsc_cnv_gistic.pkl\n",
      "37701975  6435440 -rw-r--r--    1 cwoest           staff            3292923584 May  9 10:59 ../../datasets/gdsc/my_datasets/joined_gdsc_geneexpr.pkl\n",
      "37867797    14480 -rw-r--r--    1 cwoest           staff             7413076 May  9 11:31 ../../datasets/gdsc/my_datasets/geneexpr_sparse.pkl\n",
      "37940951     1504 -rw-r--r--    1 cwoest           staff              769884 May  9 16:27 ../../datasets/gdsc/my_datasets/drug_name_fingerprints.pkl\n",
      "37700990  7681336 -rw-r--r--    1 cwoest           staff            3932841931 May  5 13:42 ../../datasets/gdsc/my_datasets/joined_gdsc_cnv_picnic.pkl\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!find ../../datasets/gdsc/my_datasets -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SAVE_DATA_TO = '../../datasets/gdsc/my_datasets/'\n",
    "\n",
    "# GDSC base table.\n",
    "GDSC_BASE_FILE = 'gdsc_base.pkl'\n",
    "\n",
    "# Cell-line feature\n",
    "CNV_GISTIC_FILE = 'joined_gdsc_cnv_gistic.pkl'\n",
    "CNV_PICNIC_FILE = 'joined_gdsc_cnv_picnic.pkl'\n",
    "GENE_EXPR_FILE = 'joined_gdsc_geneexpr.pkl'\n",
    "\n",
    "# Drug features\n",
    "FINGERPRINTS_FILE = 'drug_name_fingerprints.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Download\n",
    "\n",
    "Download data created by the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `gdsc_base.pkl` took 0.07293 seconds to import. \n",
      "Shape: (446521, 14)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gdsc_base = pd.read_pickle(f'{PATH_TO_SAVE_DATA_TO}{GDSC_BASE_FILE}')\n",
    "print(f\"File `{GDSC_BASE_FILE}` took {time.time()-start:.5f} seconds to import. \\nShape: {gdsc_base.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `joined_gdsc_cnv_gistic.pkl` took 73.98715 seconds to import. \n",
      "Shape: (446521, 952)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cnv_gistic = pd.read_pickle(f'{PATH_TO_SAVE_DATA_TO}{CNV_GISTIC_FILE}')\n",
    "print(f\"File `{CNV_GISTIC_FILE}` took {time.time()-start:.5f} seconds to import. \\nShape: {cnv_gistic.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `joined_gdsc_cnv_picnic.pkl` took 80.10469 seconds to import. \n",
      "Shape: (446521, 980)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "cnv_picnic = pd.read_pickle(f'{PATH_TO_SAVE_DATA_TO}{CNV_PICNIC_FILE}')\n",
    "print(f\"File `{CNV_PICNIC_FILE}` took {time.time()-start:.5f} seconds to import. \\nShape: {cnv_picnic.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `joined_gdsc_geneexpr.pkl` took 4.24449 seconds to import. \n",
      "Shape: (446521, 922)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gene_expr = pd.read_pickle(f'{PATH_TO_SAVE_DATA_TO}{GENE_EXPR_FILE}')\n",
    "print(f\"File `{GENE_EXPR_FILE}` took {time.time()-start:.5f} seconds to import. \\nShape: {gene_expr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File `drug_name_fingerprints.pkl` took 0.05682 seconds to import. \n",
      "Length: 449\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "fingerprints = pd.read_pickle(f'{PATH_TO_SAVE_DATA_TO}{FINGERPRINTS_FILE}')\n",
    "print(f\"File `{FINGERPRINTS_FILE}` took {time.time()-start:.5f} seconds to import. \\nLength: {len(fingerprints)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    GDSC base    : (446521, 14)\n",
      "    CNV Gistic   : (446521, 952)\n",
      "    CNV Picnic   : (446521, 980)\n",
      "    Gene Expr    : (446521, 922)\n",
      "    Fingerprints : 449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    GDSC base    : {gdsc_base.shape}\n",
    "    CNV Gistic   : {cnv_gistic.shape}\n",
    "    CNV Picnic   : {cnv_picnic.shape}\n",
    "    Gene Expr    : {gene_expr.shape}\n",
    "    Fingerprints : {len(fingerprints)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Simple Model - Gene Expression Only\n",
    "\n",
    "First, we try to create a simple Neural Network using the gene expression information only. Meaning, we will only use table `gene_expr`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DRUG_ID</th>\n",
       "      <th>CELL_LINE_NAME</th>\n",
       "      <th>AUC</th>\n",
       "      <th>CELL_ID</th>\n",
       "      <th>LN_IC50</th>\n",
       "      <th>CONC</th>\n",
       "      <th>MASTER_CELL_ID</th>\n",
       "      <th>INTENSITY</th>\n",
       "      <th>DATASET</th>\n",
       "      <th>Z_SCORE</th>\n",
       "      <th>...</th>\n",
       "      <th>MYCBP</th>\n",
       "      <th>FIS1</th>\n",
       "      <th>IFRD2</th>\n",
       "      <th>NPEPL1</th>\n",
       "      <th>CEBPD</th>\n",
       "      <th>PLEKHM1</th>\n",
       "      <th>MIF</th>\n",
       "      <th>PRAF2</th>\n",
       "      <th>LYN</th>\n",
       "      <th>POLG2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MC-CAR</td>\n",
       "      <td>0.982114</td>\n",
       "      <td>3137</td>\n",
       "      <td>2.395685</td>\n",
       "      <td>2.0</td>\n",
       "      <td>49</td>\n",
       "      <td>544404</td>\n",
       "      <td>GDSC1</td>\n",
       "      <td>-0.189576</td>\n",
       "      <td>...</td>\n",
       "      <td>8.355826</td>\n",
       "      <td>8.951680</td>\n",
       "      <td>7.205590</td>\n",
       "      <td>3.277948</td>\n",
       "      <td>3.465672</td>\n",
       "      <td>6.312806</td>\n",
       "      <td>12.112498</td>\n",
       "      <td>3.010237</td>\n",
       "      <td>8.750848</td>\n",
       "      <td>6.199366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>ES3</td>\n",
       "      <td>0.984816</td>\n",
       "      <td>2366</td>\n",
       "      <td>3.140923</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1342</td>\n",
       "      <td>404197</td>\n",
       "      <td>GDSC1</td>\n",
       "      <td>0.508635</td>\n",
       "      <td>...</td>\n",
       "      <td>5.995760</td>\n",
       "      <td>9.337588</td>\n",
       "      <td>7.468226</td>\n",
       "      <td>3.716270</td>\n",
       "      <td>5.363887</td>\n",
       "      <td>6.188079</td>\n",
       "      <td>12.281947</td>\n",
       "      <td>4.794624</td>\n",
       "      <td>3.588528</td>\n",
       "      <td>6.785201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>ES5</td>\n",
       "      <td>0.985693</td>\n",
       "      <td>2368</td>\n",
       "      <td>3.968757</td>\n",
       "      <td>2.0</td>\n",
       "      <td>610</td>\n",
       "      <td>797378</td>\n",
       "      <td>GDSC1</td>\n",
       "      <td>1.284229</td>\n",
       "      <td>...</td>\n",
       "      <td>6.939741</td>\n",
       "      <td>8.688176</td>\n",
       "      <td>7.085349</td>\n",
       "      <td>3.688222</td>\n",
       "      <td>4.572119</td>\n",
       "      <td>6.345090</td>\n",
       "      <td>12.276166</td>\n",
       "      <td>4.114092</td>\n",
       "      <td>5.768098</td>\n",
       "      <td>7.505155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 922 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DRUG_ID CELL_LINE_NAME       AUC  CELL_ID   LN_IC50  CONC  MASTER_CELL_ID  \\\n",
       "0         1         MC-CAR  0.982114     3137  2.395685   2.0              49   \n",
       "9         1            ES3  0.984816     2366  3.140923   2.0            1342   \n",
       "27        1            ES5  0.985693     2368  3.968757   2.0             610   \n",
       "\n",
       "    INTENSITY DATASET   Z_SCORE  ...     MYCBP      FIS1     IFRD2    NPEPL1  \\\n",
       "0      544404   GDSC1 -0.189576  ...  8.355826  8.951680  7.205590  3.277948   \n",
       "9      404197   GDSC1  0.508635  ...  5.995760  9.337588  7.468226  3.716270   \n",
       "27     797378   GDSC1  1.284229  ...  6.939741  8.688176  7.085349  3.688222   \n",
       "\n",
       "       CEBPD   PLEKHM1        MIF     PRAF2       LYN     POLG2  \n",
       "0   3.465672  6.312806  12.112498  3.010237  8.750848  6.199366  \n",
       "9   5.363887  6.188079  12.281947  4.794624  3.588528  6.785201  \n",
       "27  4.572119  6.345090  12.276166  4.114092  5.768098  7.505155  \n",
       "\n",
       "[3 rows x 922 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_expr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LN_IC50</th>\n",
       "      <th>CONC</th>\n",
       "      <th>INTENSITY</th>\n",
       "      <th>TSPAN6</th>\n",
       "      <th>SCYL3</th>\n",
       "      <th>BAD</th>\n",
       "      <th>LAP3</th>\n",
       "      <th>SNX11</th>\n",
       "      <th>CASP10</th>\n",
       "      <th>CFLAR</th>\n",
       "      <th>...</th>\n",
       "      <th>MYCBP</th>\n",
       "      <th>FIS1</th>\n",
       "      <th>IFRD2</th>\n",
       "      <th>NPEPL1</th>\n",
       "      <th>CEBPD</th>\n",
       "      <th>PLEKHM1</th>\n",
       "      <th>MIF</th>\n",
       "      <th>PRAF2</th>\n",
       "      <th>LYN</th>\n",
       "      <th>POLG2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.395685</td>\n",
       "      <td>2.0</td>\n",
       "      <td>544404</td>\n",
       "      <td>3.238273</td>\n",
       "      <td>4.856061</td>\n",
       "      <td>5.900525</td>\n",
       "      <td>8.120975</td>\n",
       "      <td>6.789716</td>\n",
       "      <td>3.593983</td>\n",
       "      <td>6.747933</td>\n",
       "      <td>...</td>\n",
       "      <td>8.355826</td>\n",
       "      <td>8.951680</td>\n",
       "      <td>7.205590</td>\n",
       "      <td>3.277948</td>\n",
       "      <td>3.465672</td>\n",
       "      <td>6.312806</td>\n",
       "      <td>12.112498</td>\n",
       "      <td>3.010237</td>\n",
       "      <td>8.750848</td>\n",
       "      <td>6.199366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.140923</td>\n",
       "      <td>2.0</td>\n",
       "      <td>404197</td>\n",
       "      <td>8.690198</td>\n",
       "      <td>4.572198</td>\n",
       "      <td>6.927127</td>\n",
       "      <td>5.595564</td>\n",
       "      <td>5.040800</td>\n",
       "      <td>2.776345</td>\n",
       "      <td>4.813174</td>\n",
       "      <td>...</td>\n",
       "      <td>5.995760</td>\n",
       "      <td>9.337588</td>\n",
       "      <td>7.468226</td>\n",
       "      <td>3.716270</td>\n",
       "      <td>5.363887</td>\n",
       "      <td>6.188079</td>\n",
       "      <td>12.281947</td>\n",
       "      <td>4.794624</td>\n",
       "      <td>3.588528</td>\n",
       "      <td>6.785201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.968757</td>\n",
       "      <td>2.0</td>\n",
       "      <td>797378</td>\n",
       "      <td>8.233101</td>\n",
       "      <td>4.749715</td>\n",
       "      <td>7.123143</td>\n",
       "      <td>5.458094</td>\n",
       "      <td>4.598347</td>\n",
       "      <td>2.900356</td>\n",
       "      <td>5.130654</td>\n",
       "      <td>...</td>\n",
       "      <td>6.939741</td>\n",
       "      <td>8.688176</td>\n",
       "      <td>7.085349</td>\n",
       "      <td>3.688222</td>\n",
       "      <td>4.572119</td>\n",
       "      <td>6.345090</td>\n",
       "      <td>12.276166</td>\n",
       "      <td>4.114092</td>\n",
       "      <td>5.768098</td>\n",
       "      <td>7.505155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 911 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LN_IC50  CONC  INTENSITY    TSPAN6     SCYL3       BAD      LAP3  \\\n",
       "0   2.395685   2.0     544404  3.238273  4.856061  5.900525  8.120975   \n",
       "9   3.140923   2.0     404197  8.690198  4.572198  6.927127  5.595564   \n",
       "27  3.968757   2.0     797378  8.233101  4.749715  7.123143  5.458094   \n",
       "\n",
       "       SNX11    CASP10     CFLAR  ...     MYCBP      FIS1     IFRD2    NPEPL1  \\\n",
       "0   6.789716  3.593983  6.747933  ...  8.355826  8.951680  7.205590  3.277948   \n",
       "9   5.040800  2.776345  4.813174  ...  5.995760  9.337588  7.468226  3.716270   \n",
       "27  4.598347  2.900356  5.130654  ...  6.939741  8.688176  7.085349  3.688222   \n",
       "\n",
       "       CEBPD   PLEKHM1        MIF     PRAF2       LYN     POLG2  \n",
       "0   3.465672  6.312806  12.112498  3.010237  8.750848  6.199366  \n",
       "9   5.363887  6.188079  12.281947  4.794624  3.588528  6.785201  \n",
       "27  4.572119  6.345090  12.276166  4.114092  5.768098  7.505155  \n",
       "\n",
       "[3 rows x 911 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_expr_base = gene_expr.loc[:, ~gene_expr.columns.isin(\n",
    "    ['DRUG_ID', \n",
    "    'CELL_LINE_NAME',\n",
    "    'CELL_ID',\n",
    "    'MASTER_CELL_ID',\n",
    "    'DATASET',\n",
    "    'Z_SCORE',\n",
    "    'DRUG_NAME',\n",
    "    'RMSE',\n",
    "    'AUC',\n",
    "    'COSMIC_ID',\n",
    "    'POSITION'])\n",
    "]\n",
    "gene_expr_base.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/cwoest/Documents/Academics/Data_Science_UP/master_thesis/material/GNN-material/06_create_base_dataset.ipynb Cell 16'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cwoest/Documents/Academics/Data_Science_UP/master_thesis/material/GNN-material/06_create_base_dataset.ipynb#ch0000055?line=0'>1</a>\u001b[0m v \u001b[39m=\u001b[39m gene_expr\u001b[39m.\u001b[39;49mloc[:, gene_expr\u001b[39m.\u001b[39;49mcolumns\u001b[39m!=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mLN_IC50\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/frame.py:10883\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m  <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/frame.py?line=10809'>10810</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m  <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/frame.py?line=10810'>10811</a>\u001b[0m \u001b[39mReturn a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[1;32m  <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/frame.py?line=10811'>10812</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/frame.py?line=10879'>10880</a>\u001b[0m \u001b[39m       ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[1;32m  <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/frame.py?line=10880'>10881</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m  <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/frame.py?line=10881'>10882</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m> <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/frame.py?line=10882'>10883</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array()\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/internals/managers.py:1589\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/internals/managers.py?line=1586'>1587</a>\u001b[0m             arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/internals/managers.py?line=1587'>1588</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/internals/managers.py?line=1588'>1589</a>\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/internals/managers.py?line=1589'>1590</a>\u001b[0m     \u001b[39m# The underlying data was copied within _interleave\u001b[39;00m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/internals/managers.py?line=1590'>1591</a>\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/internals/managers.py:1638\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/internals/managers.py?line=1635'>1636</a>\u001b[0m         arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mget_values(dtype)\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/internals/managers.py?line=1636'>1637</a>\u001b[0m         result[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m arr\n\u001b[0;32m-> <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/internals/managers.py?line=1637'>1638</a>\u001b[0m         itemmask[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/internals/managers.py?line=1638'>1639</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m   <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/pandas/core/internals/managers.py?line=1640'>1641</a>\u001b[0m \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "v = gene_expr.loc[:, gene_expr.columns!='LN_IC50'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = gene_expr.loc[:, ~gene_expr.columns.isin(['LN_IC50'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'LN_IC50' in gene_expr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = gene_expr['LN_IC50'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20435448"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_expr_base.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 446521 entries, 0 to 5707264\n",
      "Columns: 911 entries, LN_IC50 to POLG2\n",
      "dtypes: float64(910), int64(1)\n",
      "memory usage: 3.0 GB\n"
     ]
    }
   ],
   "source": [
    "gene_expr_base.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(446521, 911)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_expr_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(424015, 911)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_nonnan = gene_expr_base.dropna()\n",
    "gene_nonnan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.00000000e+00, 5.44404000e+05, 3.23827251e+00, ...,\n",
       "        3.01023733e+00, 8.75084800e+00, 6.19936581e+00],\n",
       "       [2.00000000e+00, 4.04197000e+05, 8.69019791e+00, ...,\n",
       "        4.79462383e+00, 3.58852758e+00, 6.78520131e+00],\n",
       "       [2.00000000e+00, 7.97378000e+05, 8.23310113e+00, ...,\n",
       "        4.11409177e+00, 5.76809818e+00, 7.50515490e+00],\n",
       "       ...,\n",
       "       [1.00000000e+01, 1.59580000e+04, 8.59362481e+00, ...,\n",
       "        3.34734214e+00, 7.21468659e+00, 6.58715604e+00],\n",
       "       [1.00000000e+01, 2.54190000e+04, 8.44162845e+00, ...,\n",
       "        3.44324413e+00, 8.34896465e+00, 6.33635721e+00],\n",
       "       [1.00000000e+01, 1.34730000e+04, 6.98164324e+00, ...,\n",
       "        4.30818433e+00, 2.91918023e+00, 6.40410310e+00]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_expr_base.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 910 # which is gene_expr_base.shape[0]-1 = 911 - 1\n",
    "                 # One value per feature\n",
    "hidden_size = 100\n",
    "num_classes = 1\n",
    "num_epochs = 2\n",
    "batch_size = 10_000\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pytorch Dataset out of the gene expression dataframe.\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GeneExpressionDataset(Dataset):\n",
    "    \"\"\"Customized class for Gene Expression data preparation.\"\"\"\n",
    "\n",
    "    def __init__(self, pd_geneexpr_dataframe: pd.DataFrame, target_name: str = 'LN_IC50'):\n",
    "        \"\"\"Initializes the dataset object.\"\"\"\n",
    "        gene_expr_df = pd_geneexpr_dataframe\n",
    "        assert target_name in gene_expr_df.columns\n",
    "\n",
    "        X = gene_expr_df.loc[:, ~gene_expr_df.columns.isin([target_name])].values\n",
    "        y = gene_expr_df[target_name].values\n",
    "\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of samples in the dataset.\"\"\"\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Loads and returns a sample from the dataset at the given index `idx`.\"\"\"\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_expr_dataset = GeneExpressionDataset(pd_geneexpr_dataframe=gene_expr_base,\n",
    "                                          target_name='LN_IC50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_split_ratio = 0.8\n",
    "\n",
    "train_size = int(train_set_split_ratio * len(gene_expr_dataset))\n",
    "test_size = len(gene_expr_dataset) - train_size\n",
    "train_set, test_set = torch.utils.data.random_split(gene_expr_dataset, \n",
    "                                                    [train_size, test_size],\n",
    "                                                    generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Shapes \n",
      "        Train : \n",
      "            X : torch.Size([446521, 910])\n",
      "            y : torch.Size([446521])\n",
      "        Test  :\n",
      "            X : torch.Size([446521, 910])\n",
      "            y : torch.Size([446521])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    Shapes \n",
    "        Train : \n",
    "            X : {train_set.dataset.X.shape}\n",
    "            y : {train_set.dataset.y.shape}\n",
    "        Test  :\n",
    "            X : {test_set.dataset.X.shape}\n",
    "            y : {test_set.dataset.y.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    i = 0\n",
      "        X = tensor([[1.0240e+01, 8.7761e+05, 7.8985e+00,  ..., 4.1138e+00, 3.1903e+00,\n",
      "         5.4369e+00],\n",
      "        [2.0000e+01, 4.3556e+05, 3.3886e+00,  ..., 4.6263e+00, 6.8246e+00,\n",
      "         6.4895e+00],\n",
      "        [1.0000e+01, 4.3293e+04, 8.2143e+00,  ..., 4.1281e+00, 6.0327e+00,\n",
      "         7.5018e+00],\n",
      "        ...,\n",
      "        [5.0000e+01, 2.3497e+07, 3.1896e+00,  ..., 3.8713e+00, 9.2537e+00,\n",
      "         5.6479e+00],\n",
      "        [2.0000e+00, 2.4176e+04, 3.6547e+00,  ..., 4.6862e+00, 5.5265e+00,\n",
      "         5.0838e+00],\n",
      "        [1.0000e+01, 9.5980e+03, 8.8486e+00,  ..., 3.4825e+00, 7.0952e+00,\n",
      "         5.9602e+00]])\n",
      "        y = tensor([5.7684, 3.7713, 6.1509,  ..., 0.9570, 3.1641, 1.3138])\n",
      "        X.size : torch.Size([10000, 910])\n",
      "        y.size : torch.Size([10000])\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(train_loader): \n",
    "    if i == 1: break\n",
    "    print(f\"\"\"\n",
    "    i = {i}\n",
    "        X = {X}\n",
    "        y = {y}\n",
    "        X.size : {X.size()}\n",
    "        y.size : {y.size()}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count : 36\n",
      "test count  : 9\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i, (X, y) in enumerate(train_loader): \n",
    "    count += 1\n",
    "print(f\"train count : {count}\") \n",
    "\n",
    "count = 0\n",
    "for i, (X, y) in enumerate(test_loader): \n",
    "    count += 1\n",
    "print(f\"test count  : {count}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 910 # which is gene_expr_base.shape[0]-1 = 911 - 1\n",
    "                 # One value per feature\n",
    "hidden_size = 100\n",
    "num_classes = 1\n",
    "num_epochs = 2\n",
    "batch_size = 10_000\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class SimpleNN_GeneExpr(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNN_GeneExpr, self).__init__()\n",
    "        print(f\"\"\"\n",
    "            input_size  = {input_size}\n",
    "            hidden_size = {hidden_size}\n",
    "            num_classes = {num_classes}\n",
    "        \"\"\")\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            input_size  = 910\n",
      "            hidden_size = 100\n",
      "            num_classes = 1\n",
      "        \n",
      "SimpleNN_GeneExpr(\n",
      "  (fc1): Linear(in_features=910, out_features=100, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=100, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNN_GeneExpr(input_size, hidden_size, num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------\n",
    "# Define Hyperparameterspace\n",
    "# --------------------------------- \n",
    "input_size = 910 # which is gene_expr_base.shape[0]-1 = 911 - 1\n",
    "                 # One value per feature\n",
    "hidden_size = 100\n",
    "num_classes = 1\n",
    "num_epochs = 10\n",
    "batch_size = 20_000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# ---------------------------------\n",
    "# Create the Dataset\n",
    "# ---------------------------------\n",
    "gene_expr_dataset = GeneExpressionDataset(pd_geneexpr_dataframe=gene_nonnan,\n",
    "                                          target_name='LN_IC50')\n",
    "\n",
    "train_set_split_ratio = 0.8\n",
    "\n",
    "train_size = int(train_set_split_ratio * len(gene_expr_dataset))\n",
    "test_size = len(gene_expr_dataset) - train_size\n",
    "train_set, test_set = torch.utils.data.random_split(gene_expr_dataset, \n",
    "                                                    [train_size, test_size],\n",
    "                                                    generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True,\n",
    "                                          num_workers=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            input_size  = 910\n",
      "            hidden_size = 64\n",
      "            num_classes = 1\n",
      "        \n",
      "SimpleNN_GeneExpr(\n",
      "  (fc1): Linear(in_features=910, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Model structure: SimpleNN_GeneExpr(\n",
      "  (fc1): Linear(in_features=910, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "Layer: fc1.weight | Size: torch.Size([64, 910]) | Values : tensor([[-0.0051, -0.0089,  0.0205,  ...,  0.0101,  0.0161,  0.0254],\n",
      "        [ 0.0147,  0.0245, -0.0131,  ..., -0.0201, -0.0057, -0.0047]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc1.bias | Size: torch.Size([64]) | Values : tensor([ 0.0226, -0.0126], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc2.weight | Size: torch.Size([1, 64]) | Values : tensor([[-0.0688, -0.0533, -0.0070,  0.0854,  0.0395, -0.0993, -0.0516, -0.0913,\n",
      "          0.1177, -0.0908, -0.0913,  0.1020,  0.0446, -0.0412,  0.1231,  0.0687,\n",
      "         -0.0239,  0.0168, -0.0387,  0.0190, -0.0681, -0.0124,  0.0306,  0.0667,\n",
      "          0.0692,  0.0750,  0.1006, -0.0059,  0.0772, -0.0347,  0.1022, -0.0426,\n",
      "          0.0736, -0.0940, -0.0334, -0.1160, -0.0326, -0.0544,  0.0228, -0.0278,\n",
      "         -0.0760,  0.0075, -0.0027, -0.0336, -0.1022,  0.0269, -0.0264,  0.0415,\n",
      "          0.0931,  0.0183, -0.0206, -0.0062,  0.0123,  0.0830, -0.0235,  0.0700,\n",
      "          0.0445,  0.0907, -0.0563, -0.0006,  0.0903, -0.0939,  0.0713, -0.1201]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc2.bias | Size: torch.Size([1]) | Values : tensor([-0.0593], grad_fn=<SliceBackward0>) \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Epoch [1/10], Step [5/17], Loss: 3121593344.0000\n",
      "Epoch [1/10], Step [10/17], Loss: 2124933376.0000\n",
      "Epoch [1/10], Step [15/17], Loss: 660577856.0000\n",
      "Epoch [2/10], Step [5/17], Loss: 489613888.0000\n",
      "Epoch [2/10], Step [10/17], Loss: 84998040.0000\n",
      "Epoch [2/10], Step [15/17], Loss: 2582779.2500\n",
      "Epoch [3/10], Step [5/17], Loss: 17453886.0000\n",
      "Epoch [3/10], Step [10/17], Loss: 395175.3125\n",
      "Epoch [3/10], Step [15/17], Loss: 6649951.5000\n",
      "Epoch [4/10], Step [5/17], Loss: 2202677.7500\n",
      "Epoch [4/10], Step [10/17], Loss: 132953.0625\n",
      "Epoch [4/10], Step [15/17], Loss: 22945.1836\n",
      "Epoch [5/10], Step [5/17], Loss: 2240937.0000\n",
      "Epoch [5/10], Step [10/17], Loss: 1447578.0000\n",
      "Epoch [5/10], Step [15/17], Loss: 832872.4375\n",
      "Epoch [6/10], Step [5/17], Loss: 156597.7812\n",
      "Epoch [6/10], Step [10/17], Loss: 56781.5195\n",
      "Epoch [6/10], Step [15/17], Loss: 10343.8623\n",
      "Epoch [7/10], Step [5/17], Loss: 95121.9141\n",
      "Epoch [7/10], Step [10/17], Loss: 58086.4531\n",
      "Epoch [7/10], Step [15/17], Loss: 28997.6621\n",
      "Epoch [8/10], Step [5/17], Loss: 5859.8711\n",
      "Epoch [8/10], Step [10/17], Loss: 7672.7148\n",
      "Epoch [8/10], Step [15/17], Loss: 5321.0986\n",
      "Epoch [9/10], Step [5/17], Loss: 519.8533\n",
      "Epoch [9/10], Step [10/17], Loss: 1082.3903\n",
      "Epoch [9/10], Step [15/17], Loss: 901.1731\n",
      "Epoch [10/10], Step [5/17], Loss: 170.9776\n",
      "Epoch [10/10], Step [10/17], Loss: 264.8016\n",
      "Epoch [10/10], Step [15/17], Loss: 133.7228\n"
     ]
    }
   ],
   "source": [
    "# ----------------- #\n",
    "# BUILD THE NETWORK #\n",
    "# ----------------- #\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class SimpleNN_GeneExpr(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNN_GeneExpr, self).__init__()\n",
    "        print(f\"\"\"\n",
    "            input_size  = {input_size}\n",
    "            hidden_size = {hidden_size}\n",
    "            num_classes = {num_classes}\n",
    "        \"\"\")\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)   # module that applies a linear transformation on the input using its stored weights and biases.\n",
    "        self.relu = nn.ReLU()                           # Non-linear activations are what create the complex mappings between the model’s inputs and outputs. No introduce nonlinearity, helping neural networks learn a wide variety of phenomena.\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleNN_GeneExpr(input_size, hidden_size=64, num_classes=num_classes).to(device)\n",
    "print(model)\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n",
    "print(100*\"-\")\n",
    "\n",
    "# Loss and optimizer\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),  # Weights of the network which needs to be updated.\n",
    "                             lr=learning_rate)    # Learning rate.\n",
    "\n",
    "# -------- #\n",
    "# TRAINING #\n",
    "# -------- #\n",
    "loss_values = []\n",
    "total_step = len(train_loader)\n",
    "it = iter(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (X_batch, y_batch) in enumerate(train_loader):  \n",
    "        #images = images.reshape(-1, 28*28).to(device)\n",
    "        #labels = labels.to(device)\n",
    "        # if i > 3: break\n",
    "\n",
    "        # Move tensors to the configured device\n",
    "        X = X_batch.to(device)  # All feature values\n",
    "        y = y_batch.to(device)  # The ln(IC50) values\n",
    "\n",
    "        assert not torch.isnan(X).any(), f\"X has NaN in it {i}.\"\n",
    "        assert not torch.isnan(y).any(), f\"y has NaN in it {i}.\"\n",
    "\n",
    "        # print(20*\"+\")\n",
    "        # print(f\"i={i}\")\n",
    "        # print(X.size())\n",
    "        # print(y.size())\n",
    "        # print(X)\n",
    "        # print(y)\n",
    "        # print(\"outputs...\")\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        loss = loss_func(outputs, y_batch)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Backward and optimize. Update the weights.\n",
    "        optimizer.zero_grad()  # We need to zero the gradients, otherwise the next batch would also need to deal \n",
    "                               # with the previous batches gradients.\n",
    "                               # This is because the calculated gradients accumulate by default.\n",
    "        loss.backward()        # Compute the gradients.\n",
    "        optimizer.step()       # Use the gradients and perform adjustment/update of the weights.\n",
    "        \n",
    "        if (i+1) % 5 == 0: # was % 100 before\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))    \n",
    "\n",
    "    loss_values.append(running_loss / len(gene_expr_dataset))                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_values, linestyle='-', marker='o', label='Train');\n",
    "plt.xlim(0, 9, 1);\n",
    "plt.xlabel(\"Epochs\");\n",
    "plt.ylabel(\"MSE\");\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66515.49451906183\n",
      "7844.23410221705\n",
      "1712.3140609707204\n",
      "286.8425378432219\n",
      "44.10569577662715\n",
      "6.826933455389347\n",
      "1.4346801996942373\n",
      "0.2648926382313463\n",
      "0.0427235598215698\n",
      "0.008080745905877767\n"
     ]
    }
   ],
   "source": [
    "for l in loss_values: \n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight tensor([[-0.0269, -0.0289,  0.0310,  ...,  0.0093, -0.0131, -0.0231],\n",
      "        [-0.0155, -0.0096, -0.0036,  ..., -0.0088,  0.0098,  0.0195],\n",
      "        [ 0.0061, -0.0083,  0.0073,  ..., -0.0298,  0.0049,  0.0245],\n",
      "        ...,\n",
      "        [-0.0231,  0.0236,  0.0253,  ..., -0.0141,  0.0007, -0.0226],\n",
      "        [-0.0111, -0.0113,  0.0097,  ..., -0.0209, -0.0089,  0.0112],\n",
      "        [-0.0198,  0.0234,  0.0064,  ..., -0.0039, -0.0163,  0.0033]])\n",
      "fc1.bias tensor([-0.0276, -0.0246, -0.0266, -0.0269, -0.0033, -0.0299, -0.0013, -0.0185,\n",
      "         0.0138, -0.0015,  0.0075, -0.0261, -0.0012, -0.0195,  0.0197,  0.0119,\n",
      "        -0.0245,  0.0285,  0.0317,  0.0275, -0.0239, -0.0060, -0.0016,  0.0263,\n",
      "         0.0138, -0.0275,  0.0059, -0.0246, -0.0264, -0.0240,  0.0010,  0.0252,\n",
      "        -0.0282, -0.0232, -0.0184,  0.0026, -0.0216, -0.0088,  0.0056, -0.0270,\n",
      "        -0.0378,  0.0226,  0.0226,  0.0072,  0.0023, -0.0321,  0.0131, -0.0111,\n",
      "        -0.0102, -0.0136, -0.0045,  0.0121, -0.0047, -0.0238,  0.0271, -0.0172,\n",
      "        -0.0134, -0.0103, -0.0109,  0.0037, -0.0090,  0.0075, -0.0068,  0.0204])\n",
      "fc2.weight tensor([[-8.1411e-02,  7.1644e-02, -9.9706e-02,  2.6776e-05, -1.1649e-01,\n",
      "          1.1832e-01,  1.0222e-01, -3.2355e-02, -5.5286e-02, -8.0706e-02,\n",
      "         -6.9941e-02,  8.0809e-02,  5.6776e-02,  5.5773e-02,  3.2670e-02,\n",
      "          4.4120e-02,  6.8061e-02, -4.0212e-02,  7.7981e-02,  1.0996e-01,\n",
      "          8.5480e-03,  4.5282e-02, -3.6753e-02,  3.1841e-02,  6.2050e-02,\n",
      "          1.3931e-02, -1.1917e-01,  7.6720e-02,  9.9224e-02,  5.0782e-03,\n",
      "         -1.8708e-02,  4.3240e-02, -2.4851e-03, -1.0368e-01,  4.5143e-02,\n",
      "         -7.4234e-02, -6.4498e-02,  1.1221e-02,  4.6230e-02, -2.3577e-02,\n",
      "         -6.1004e-02, -8.3285e-02, -1.7648e-03,  6.6641e-02, -1.7389e-02,\n",
      "         -1.1385e-01, -3.6293e-02, -1.2159e-01, -4.9431e-03,  9.7645e-02,\n",
      "         -1.0349e-02,  1.1655e-01,  7.2179e-02,  3.0129e-02,  7.8993e-02,\n",
      "          5.5161e-02,  3.5170e-02, -4.3846e-02,  2.0443e-04,  4.8420e-02,\n",
      "         -9.9522e-02, -1.9701e-02, -9.4085e-02, -2.7696e-02]])\n",
      "fc2.bias tensor([0.1211])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424015"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset.dataset.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 910])\n",
      "tensor([5.0000e+00, 1.6405e+05, 7.7230e+00, 3.8891e+00, 7.0276e+00, 7.1788e+00,\n",
      "        4.5978e+00, 2.9991e+00, 5.7122e+00, 7.3056e+00, 5.0119e+00, 5.5608e+00,\n",
      "        5.0372e+00, 5.9888e+00, 8.3537e+00, 8.2142e+00, 3.4273e+00, 3.1605e+00,\n",
      "        6.7381e+00, 7.3724e+00, 7.4720e+00, 7.4916e+00, 6.9882e+00, 3.4057e+00,\n",
      "        8.5154e+00, 3.5651e+00, 4.2408e+00, 8.2399e+00, 6.6031e+00, 2.6824e+00,\n",
      "        3.8723e+00, 6.0092e+00, 4.2084e+00, 6.1314e+00, 7.8983e+00, 9.1007e+00,\n",
      "        3.8978e+00, 4.6455e+00, 8.1857e+00, 6.1570e+00, 7.6178e+00, 6.9075e+00,\n",
      "        8.0815e+00, 7.8934e+00, 9.4280e+00, 7.3091e+00, 4.6702e+00, 1.0381e+01,\n",
      "        8.1890e+00, 8.1509e+00, 9.9711e+00, 6.3114e+00, 6.4095e+00, 2.6861e+00,\n",
      "        8.6869e+00, 7.0460e+00, 6.1478e+00, 8.4304e+00, 5.5530e+00, 8.5280e+00,\n",
      "        5.5426e+00, 9.4177e+00, 4.8715e+00, 6.3504e+00, 5.3794e+00, 8.6218e+00,\n",
      "        4.4241e+00, 5.5954e+00, 3.7659e+00, 3.4134e+00, 6.3883e+00, 7.5156e+00,\n",
      "        5.4214e+00, 8.4898e+00, 7.8857e+00, 3.2003e+00, 4.5581e+00, 7.1813e+00,\n",
      "        5.9231e+00, 7.7191e+00, 2.9549e+00, 1.0078e+01, 6.3074e+00, 6.9804e+00,\n",
      "        2.9996e+00, 8.4429e+00, 5.3472e+00, 3.1104e+00, 7.6139e+00, 9.2105e+00,\n",
      "        4.2274e+00, 1.0879e+01, 9.4286e+00, 6.1927e+00, 6.0900e+00, 6.9827e+00,\n",
      "        5.5683e+00, 7.2076e+00, 5.4091e+00, 8.5944e+00, 4.2756e+00, 7.5467e+00,\n",
      "        3.5817e+00, 7.6517e+00, 4.4826e+00, 4.3378e+00, 7.3372e+00, 7.6342e+00,\n",
      "        3.2728e+00, 3.0777e+00, 4.8526e+00, 9.0984e+00, 1.0803e+01, 5.8230e+00,\n",
      "        4.7859e+00, 3.4712e+00, 6.2547e+00, 2.7402e+00, 8.2403e+00, 3.1455e+00,\n",
      "        8.3721e+00, 7.0272e+00, 3.2611e+00, 3.2007e+00, 8.7213e+00, 3.7587e+00,\n",
      "        3.9687e+00, 1.0051e+01, 8.8123e+00, 7.7698e+00, 4.5997e+00, 4.0361e+00,\n",
      "        9.8034e+00, 6.7992e+00, 8.0520e+00, 8.2579e+00, 7.8106e+00, 7.7218e+00,\n",
      "        4.1833e+00, 3.5080e+00, 7.3817e+00, 5.6421e+00, 2.9968e+00, 2.7528e+00,\n",
      "        7.8373e+00, 9.4042e+00, 7.3153e+00, 9.2995e+00, 5.4508e+00, 3.9134e+00,\n",
      "        1.2145e+01, 9.6824e+00, 8.7805e+00, 5.2879e+00, 7.5193e+00, 7.9378e+00,\n",
      "        7.2640e+00, 4.9018e+00, 5.9908e+00, 6.3472e+00, 7.5579e+00, 1.1493e+01,\n",
      "        7.4386e+00, 1.0459e+01, 8.0694e+00, 8.4796e+00, 4.2591e+00, 6.9986e+00,\n",
      "        4.7788e+00, 7.7015e+00, 3.1528e+00, 5.0023e+00, 8.7947e+00, 8.4771e+00,\n",
      "        3.3599e+00, 7.7846e+00, 1.0000e+01, 3.1755e+00, 6.6088e+00, 6.0602e+00,\n",
      "        4.3883e+00, 5.7759e+00, 8.5024e+00, 6.5438e+00, 7.9996e+00, 8.3258e+00,\n",
      "        5.6873e+00, 6.0661e+00, 8.6890e+00, 9.2171e+00, 7.5872e+00, 6.0871e+00,\n",
      "        4.1080e+00, 7.8402e+00, 8.8311e+00, 6.9163e+00, 9.1462e+00, 8.6870e+00,\n",
      "        5.9079e+00, 6.5995e+00, 6.9502e+00, 7.4703e+00, 8.3344e+00, 5.2559e+00,\n",
      "        7.2719e+00, 3.0786e+00, 3.4469e+00, 6.5164e+00, 8.2747e+00, 6.3070e+00,\n",
      "        5.5913e+00, 7.0327e+00, 5.8071e+00, 6.0420e+00, 7.6413e+00, 5.4750e+00,\n",
      "        1.0121e+01, 1.0234e+01, 4.3456e+00, 1.0729e+01, 4.8077e+00, 7.5405e+00,\n",
      "        3.1822e+00, 6.1709e+00, 7.3522e+00, 9.2152e+00, 4.3245e+00, 7.3626e+00,\n",
      "        3.8005e+00, 4.0664e+00, 3.7872e+00, 6.6614e+00, 8.2837e+00, 5.8579e+00,\n",
      "        5.1730e+00, 6.7811e+00, 3.8725e+00, 5.4263e+00, 8.4823e+00, 1.0219e+01,\n",
      "        4.6000e+00, 7.9922e+00, 5.7237e+00, 8.9825e+00, 4.9716e+00, 8.8096e+00,\n",
      "        3.9615e+00, 4.5021e+00, 8.1191e+00, 6.9806e+00, 5.9960e+00, 5.1199e+00,\n",
      "        3.2731e+00, 9.9959e+00, 9.3592e+00, 5.0220e+00, 5.5741e+00, 5.3109e+00,\n",
      "        6.8338e+00, 9.1559e+00, 5.4694e+00, 7.8777e+00, 7.6644e+00, 3.5291e+00,\n",
      "        4.6393e+00, 7.3286e+00, 8.9947e+00, 4.7538e+00, 9.6250e+00, 3.9282e+00,\n",
      "        3.1783e+00, 1.0228e+01, 5.5733e+00, 6.6088e+00, 4.6208e+00, 7.4257e+00,\n",
      "        5.7517e+00, 7.0408e+00, 5.8245e+00, 5.5135e+00, 9.9807e+00, 3.7504e+00,\n",
      "        4.6213e+00, 8.5605e+00, 6.0093e+00, 8.6930e+00, 8.4902e+00, 4.5743e+00,\n",
      "        6.5848e+00, 4.6965e+00, 6.8051e+00, 8.5218e+00, 5.2914e+00, 4.6858e+00,\n",
      "        3.2730e+00, 7.3968e+00, 5.6783e+00, 4.9192e+00, 8.0140e+00, 7.2397e+00,\n",
      "        6.9612e+00, 4.2762e+00, 5.1731e+00, 5.4166e+00, 6.8653e+00, 9.1719e+00,\n",
      "        4.3951e+00, 6.7821e+00, 6.1644e+00, 5.8530e+00, 8.1215e+00, 8.4226e+00,\n",
      "        5.1110e+00, 5.3597e+00, 8.2940e+00, 6.8941e+00, 7.0462e+00, 7.3623e+00,\n",
      "        1.3104e+01, 7.0154e+00, 3.8298e+00, 7.5906e+00, 6.2257e+00, 3.2968e+00,\n",
      "        8.3191e+00, 4.9226e+00, 3.8058e+00, 9.5821e+00, 4.2320e+00, 6.1204e+00,\n",
      "        4.1587e+00, 5.6560e+00, 4.4607e+00, 2.9166e+00, 8.3253e+00, 1.0084e+01,\n",
      "        7.5445e+00, 8.6579e+00, 7.5809e+00, 7.0912e+00, 9.0382e+00, 8.6694e+00,\n",
      "        7.0198e+00, 9.9448e+00, 7.5635e+00, 4.1335e+00, 7.6553e+00, 7.7148e+00,\n",
      "        4.0236e+00, 5.6054e+00, 5.0198e+00, 9.2309e+00, 6.4839e+00, 5.1503e+00,\n",
      "        8.2335e+00, 4.2936e+00, 7.1300e+00, 9.0241e+00, 6.1912e+00, 4.5784e+00,\n",
      "        9.8304e+00, 4.5151e+00, 6.7815e+00, 9.9836e+00, 7.7569e+00, 6.1879e+00,\n",
      "        7.8038e+00, 5.3811e+00, 8.0341e+00, 3.7527e+00, 3.5097e+00, 1.0664e+01,\n",
      "        5.9181e+00, 8.0867e+00, 7.6975e+00, 9.2299e+00, 6.3334e+00, 7.1928e+00,\n",
      "        8.1445e+00, 7.7797e+00, 4.2157e+00, 8.5365e+00, 3.5396e+00, 5.1873e+00,\n",
      "        7.9775e+00, 4.3339e+00, 5.1652e+00, 8.1413e+00, 8.3540e+00, 6.8088e+00,\n",
      "        6.7496e+00, 5.2867e+00, 6.0156e+00, 6.9955e+00, 8.5251e+00, 1.1360e+01,\n",
      "        5.5588e+00, 8.0784e+00, 5.7467e+00, 9.6325e+00, 3.0512e+00, 3.7503e+00,\n",
      "        7.0788e+00, 8.5262e+00, 9.8982e+00, 9.6863e+00, 8.1303e+00, 7.6488e+00,\n",
      "        6.3582e+00, 6.1194e+00, 4.0742e+00, 8.0770e+00, 3.5652e+00, 3.7590e+00,\n",
      "        2.8930e+00, 8.7095e+00, 8.1377e+00, 5.2958e+00, 6.3672e+00, 7.3450e+00,\n",
      "        2.8658e+00, 7.6311e+00, 5.0861e+00, 7.1259e+00, 8.4500e+00, 6.4476e+00,\n",
      "        6.1605e+00, 6.4577e+00, 6.1688e+00, 4.8468e+00, 9.2931e+00, 8.2559e+00,\n",
      "        3.7026e+00, 8.5010e+00, 9.4960e+00, 5.1272e+00, 7.2589e+00, 5.7951e+00,\n",
      "        4.6381e+00, 3.0936e+00, 3.4529e+00, 5.9862e+00, 8.3970e+00, 9.3004e+00,\n",
      "        6.9713e+00, 8.9232e+00, 5.5300e+00, 7.7534e+00, 3.7689e+00, 5.8400e+00,\n",
      "        8.3358e+00, 5.2824e+00, 9.4945e+00, 6.7043e+00, 7.8609e+00, 9.2997e+00,\n",
      "        8.8080e+00, 6.6764e+00, 1.0151e+01, 3.3668e+00, 6.7202e+00, 7.5316e+00,\n",
      "        8.3490e+00, 8.5153e+00, 8.7581e+00, 7.6977e+00, 8.7996e+00, 9.1567e+00,\n",
      "        3.0874e+00, 6.0595e+00, 3.0035e+00, 4.1330e+00, 8.8163e+00, 5.5010e+00,\n",
      "        7.6868e+00, 5.0337e+00, 8.9457e+00, 7.7209e+00, 1.0050e+01, 7.0169e+00,\n",
      "        6.5493e+00, 6.9043e+00, 6.6136e+00, 5.2510e+00, 4.3140e+00, 6.5390e+00,\n",
      "        2.8391e+00, 1.0343e+01, 5.4496e+00, 4.5676e+00, 5.7098e+00, 3.6576e+00,\n",
      "        3.9493e+00, 6.8291e+00, 1.0382e+01, 5.1224e+00, 6.5623e+00, 9.7174e+00,\n",
      "        9.9735e+00, 7.9977e+00, 4.5017e+00, 3.3549e+00, 4.6744e+00, 8.8701e+00,\n",
      "        5.4342e+00, 5.0070e+00, 7.4269e+00, 7.3679e+00, 5.4214e+00, 5.8185e+00,\n",
      "        9.2593e+00, 7.3697e+00, 3.4387e+00, 5.6394e+00, 6.3946e+00, 3.3000e+00,\n",
      "        5.7886e+00, 9.1730e+00, 5.9174e+00, 9.9814e+00, 7.8277e+00, 9.2831e+00,\n",
      "        8.5700e+00, 6.6982e+00, 4.9196e+00, 3.7775e+00, 6.9368e+00, 5.1924e+00,\n",
      "        6.4024e+00, 1.0385e+01, 1.1934e+01, 5.5366e+00, 4.1737e+00, 4.9594e+00,\n",
      "        1.0234e+01, 8.4627e+00, 5.7348e+00, 4.2715e+00, 9.3044e+00, 8.6998e+00,\n",
      "        3.4034e+00, 5.8665e+00, 3.9747e+00, 5.6717e+00, 1.0553e+01, 4.4846e+00,\n",
      "        7.9363e+00, 8.7658e+00, 3.1663e+00, 6.5752e+00, 4.3472e+00, 5.0901e+00,\n",
      "        9.4828e+00, 9.7793e+00, 7.8727e+00, 6.9667e+00, 4.2022e+00, 9.2740e+00,\n",
      "        3.2983e+00, 4.7403e+00, 6.4180e+00, 5.6795e+00, 1.0241e+01, 5.8445e+00,\n",
      "        3.0343e+00, 8.6907e+00, 5.1124e+00, 3.8764e+00, 3.1164e+00, 4.2462e+00,\n",
      "        4.8587e+00, 6.4313e+00, 8.9931e+00, 4.5609e+00, 8.6762e+00, 3.5467e+00,\n",
      "        8.5593e+00, 7.8400e+00, 7.2848e+00, 9.0972e+00, 8.1743e+00, 8.8269e+00,\n",
      "        7.5785e+00, 5.0360e+00, 5.7740e+00, 3.8530e+00, 4.0241e+00, 6.6091e+00,\n",
      "        3.2837e+00, 3.8713e+00, 6.7925e+00, 5.4090e+00, 6.7943e+00, 6.5869e+00,\n",
      "        7.8137e+00, 7.3886e+00, 4.3213e+00, 5.1981e+00, 9.8652e+00, 4.4415e+00,\n",
      "        8.0227e+00, 6.4493e+00, 9.1543e+00, 4.4335e+00, 6.9932e+00, 9.1066e+00,\n",
      "        5.1405e+00, 9.7773e+00, 4.4003e+00, 6.5465e+00, 5.6653e+00, 5.8466e+00,\n",
      "        6.0156e+00, 6.2083e+00, 5.2941e+00, 9.0589e+00, 8.5242e+00, 1.0106e+01,\n",
      "        3.3591e+00, 3.2218e+00, 3.9146e+00, 8.5018e+00, 6.9517e+00, 3.9240e+00,\n",
      "        7.8862e+00, 6.6528e+00, 5.6085e+00, 4.3080e+00, 1.1968e+01, 3.3243e+00,\n",
      "        7.8229e+00, 1.1615e+01, 4.4619e+00, 8.4154e+00, 4.6758e+00, 9.1840e+00,\n",
      "        7.1253e+00, 6.8298e+00, 8.9708e+00, 8.5195e+00, 7.8991e+00, 4.6627e+00,\n",
      "        8.1540e+00, 4.9519e+00, 4.8971e+00, 3.9593e+00, 7.5038e+00, 5.5633e+00,\n",
      "        9.1113e+00, 6.6887e+00, 4.5805e+00, 7.3886e+00, 8.3848e+00, 9.3924e+00,\n",
      "        4.7998e+00, 3.2955e+00, 3.5297e+00, 5.9936e+00, 6.2204e+00, 3.7166e+00,\n",
      "        2.8445e+00, 6.5643e+00, 4.3247e+00, 4.6628e+00, 4.0250e+00, 5.8499e+00,\n",
      "        5.2762e+00, 8.9126e+00, 7.7265e+00, 1.0057e+01, 6.0062e+00, 5.7264e+00,\n",
      "        7.5039e+00, 4.1111e+00, 7.1690e+00, 4.0899e+00, 5.0789e+00, 8.4104e+00,\n",
      "        4.7404e+00, 3.4460e+00, 6.3608e+00, 8.1593e+00, 1.1021e+01, 5.0076e+00,\n",
      "        8.0111e+00, 5.6931e+00, 3.9179e+00, 3.9791e+00, 9.2750e+00, 8.3386e+00,\n",
      "        6.8970e+00, 4.7545e+00, 5.1980e+00, 6.1840e+00, 7.6008e+00, 5.6990e+00,\n",
      "        7.6608e+00, 6.5492e+00, 4.0209e+00, 6.1758e+00, 8.3565e+00, 8.9856e+00,\n",
      "        3.0999e+00, 5.2339e+00, 8.1144e+00, 4.5853e+00, 2.9962e+00, 9.9684e+00,\n",
      "        8.6617e+00, 6.7697e+00, 3.3135e+00, 7.2230e+00, 3.2375e+00, 4.4254e+00,\n",
      "        4.9353e+00, 4.2130e+00, 7.0001e+00, 9.7725e+00, 7.6168e+00, 9.4275e+00,\n",
      "        1.0353e+01, 5.1499e+00, 4.5861e+00, 9.8779e+00, 6.6050e+00, 7.2949e+00,\n",
      "        4.2527e+00, 7.2104e+00, 7.4069e+00, 4.2695e+00, 7.6364e+00, 8.3255e+00,\n",
      "        4.9968e+00, 8.3864e+00, 4.0006e+00, 6.2861e+00, 6.1989e+00, 3.2834e+00,\n",
      "        6.2516e+00, 5.8286e+00, 6.9322e+00, 5.8837e+00, 5.4610e+00, 5.6622e+00,\n",
      "        8.7425e+00, 1.0003e+01, 6.0365e+00, 2.7891e+00, 6.7916e+00, 5.5352e+00,\n",
      "        9.5424e+00, 8.5779e+00, 6.4315e+00, 6.6357e+00, 8.7932e+00, 4.5167e+00,\n",
      "        7.0889e+00, 6.9475e+00, 8.0037e+00, 3.4234e+00, 3.6229e+00, 1.0066e+01,\n",
      "        8.4116e+00, 4.1813e+00, 9.2081e+00, 8.7983e+00, 5.7752e+00, 8.1433e+00,\n",
      "        5.7133e+00, 9.4769e+00, 3.9125e+00, 7.7905e+00, 6.3868e+00, 4.6467e+00,\n",
      "        6.0536e+00, 5.5983e+00, 5.7288e+00, 5.5982e+00, 4.9214e+00, 7.7548e+00,\n",
      "        3.3550e+00, 6.8575e+00, 5.2985e+00, 4.4027e+00, 3.8131e+00, 4.9659e+00,\n",
      "        7.1691e+00, 9.3298e+00, 4.7811e+00, 4.7900e+00, 8.0367e+00, 4.2682e+00,\n",
      "        7.9399e+00, 3.3789e+00, 1.0620e+01, 5.3640e+00, 6.3082e+00, 8.4152e+00,\n",
      "        8.6579e+00, 5.9692e+00, 6.6329e+00, 8.0041e+00, 8.3637e+00, 3.9946e+00,\n",
      "        1.0888e+01, 4.7510e+00, 3.3234e+00, 4.1619e+00, 4.2313e+00, 7.2531e+00,\n",
      "        5.7621e+00, 7.9141e+00, 5.3181e+00, 8.2106e+00, 7.9045e+00, 7.5215e+00,\n",
      "        8.4947e+00, 3.9915e+00, 6.3549e+00, 9.2590e+00, 5.8759e+00, 7.7673e+00,\n",
      "        4.0007e+00, 8.6709e+00, 8.9033e+00, 7.7392e+00, 8.4067e+00, 6.9263e+00,\n",
      "        7.3029e+00, 4.6038e+00, 5.3484e+00, 9.2653e+00, 1.0037e+01, 3.5802e+00,\n",
      "        4.5318e+00, 6.0077e+00, 5.7482e+00, 7.2233e+00, 3.3636e+00, 4.5350e+00,\n",
      "        4.5317e+00, 3.7069e+00, 3.0985e+00, 8.9666e+00, 5.8642e+00, 7.3966e+00,\n",
      "        7.7568e+00, 7.4780e+00, 6.9810e+00, 9.0533e+00, 6.2262e+00, 6.4652e+00,\n",
      "        8.4744e+00, 9.9354e+00, 6.9853e+00, 8.5528e+00, 4.9262e+00, 7.4856e+00,\n",
      "        3.3446e+00, 2.9970e+00, 7.9901e+00, 4.5803e+00, 3.3601e+00, 8.5920e+00,\n",
      "        4.3383e+00, 4.3936e+00, 9.9116e+00, 5.7646e+00, 8.5688e+00, 4.1097e+00,\n",
      "        8.6539e+00, 9.4817e+00, 5.6577e+00, 6.1296e+00, 7.1885e+00, 4.0171e+00,\n",
      "        6.8322e+00, 9.6312e+00, 4.0066e+00, 5.5410e+00, 8.8266e+00, 8.4339e+00,\n",
      "        7.6316e+00, 3.3264e+00, 6.9340e+00, 8.0658e+00, 2.9796e+00, 3.5211e+00,\n",
      "        1.0884e+01, 7.9772e+00, 5.7605e+00, 4.9912e+00, 5.4710e+00, 8.5723e+00,\n",
      "        6.3894e+00, 5.5866e+00, 7.9757e+00, 7.1598e+00, 7.6992e+00, 6.9973e+00,\n",
      "        7.6617e+00, 7.9859e+00, 7.4586e+00, 4.1486e+00, 9.3260e+00, 7.2541e+00,\n",
      "        1.2579e+01, 3.1438e+00, 7.4611e+00, 6.2264e+00])\n",
      "torch.Size([20000])\n",
      "torch.Size([20000, 910])\n",
      "tensor([1.6000e+01, 5.0964e+04, 3.3528e+00, 4.5759e+00, 5.5767e+00, 6.5311e+00,\n",
      "        5.0238e+00, 3.0094e+00, 3.7428e+00, 7.7165e+00, 6.4655e+00, 5.3495e+00,\n",
      "        6.2151e+00, 6.2000e+00, 9.0788e+00, 6.5243e+00, 3.0344e+00, 3.3850e+00,\n",
      "        8.0237e+00, 8.9541e+00, 7.5563e+00, 8.6466e+00, 7.5915e+00, 8.1167e+00,\n",
      "        7.8650e+00, 3.4388e+00, 4.8105e+00, 8.9826e+00, 6.9050e+00, 9.9288e+00,\n",
      "        6.1963e+00, 6.1915e+00, 5.4930e+00, 7.0298e+00, 4.5937e+00, 4.8683e+00,\n",
      "        3.1380e+00, 5.0210e+00, 7.7881e+00, 5.1182e+00, 5.8215e+00, 7.3052e+00,\n",
      "        6.4116e+00, 6.9526e+00, 8.8632e+00, 7.4313e+00, 4.1118e+00, 3.2987e+00,\n",
      "        8.5543e+00, 8.3143e+00, 5.2479e+00, 2.8329e+00, 5.7689e+00, 2.8699e+00,\n",
      "        3.3769e+00, 8.7412e+00, 5.6821e+00, 8.6810e+00, 5.8652e+00, 8.7554e+00,\n",
      "        3.1191e+00, 8.9120e+00, 6.1849e+00, 6.8125e+00, 6.0736e+00, 9.6926e+00,\n",
      "        3.4089e+00, 5.8668e+00, 4.1144e+00, 3.3230e+00, 6.4284e+00, 4.0300e+00,\n",
      "        6.0513e+00, 6.8145e+00, 5.3266e+00, 3.1085e+00, 3.9956e+00, 6.0700e+00,\n",
      "        7.0360e+00, 5.1000e+00, 3.1270e+00, 1.0959e+01, 7.0647e+00, 8.1073e+00,\n",
      "        3.1131e+00, 8.6101e+00, 4.6501e+00, 4.6659e+00, 7.4733e+00, 9.1803e+00,\n",
      "        3.7843e+00, 1.0633e+01, 1.0009e+01, 6.3680e+00, 7.6991e+00, 6.7845e+00,\n",
      "        5.5010e+00, 4.1873e+00, 6.0718e+00, 9.0738e+00, 4.4208e+00, 8.8679e+00,\n",
      "        2.9089e+00, 7.7741e+00, 4.4614e+00, 3.9556e+00, 6.7289e+00, 5.9347e+00,\n",
      "        3.4713e+00, 3.0574e+00, 6.9023e+00, 1.0478e+01, 4.7063e+00, 7.4717e+00,\n",
      "        4.5618e+00, 3.7508e+00, 7.4273e+00, 2.6673e+00, 3.5083e+00, 3.1269e+00,\n",
      "        8.9985e+00, 5.6635e+00, 3.3246e+00, 3.2406e+00, 8.0407e+00, 3.6047e+00,\n",
      "        3.3730e+00, 9.8515e+00, 8.1335e+00, 3.2354e+00, 5.7923e+00, 3.6372e+00,\n",
      "        1.0272e+01, 8.0086e+00, 7.9125e+00, 6.6387e+00, 7.5445e+00, 8.5125e+00,\n",
      "        5.3864e+00, 3.9395e+00, 3.8036e+00, 3.4963e+00, 4.0577e+00, 9.1576e+00,\n",
      "        9.0512e+00, 4.8829e+00, 8.3323e+00, 1.0830e+01, 6.8648e+00, 4.9982e+00,\n",
      "        1.2827e+01, 3.8391e+00, 8.3974e+00, 5.2422e+00, 7.7686e+00, 6.5328e+00,\n",
      "        3.7333e+00, 6.7516e+00, 4.6200e+00, 6.4188e+00, 3.6598e+00, 1.2140e+01,\n",
      "        8.7308e+00, 1.0506e+01, 6.7635e+00, 9.3683e+00, 4.4032e+00, 8.0344e+00,\n",
      "        3.5691e+00, 8.4642e+00, 3.7362e+00, 5.0372e+00, 9.0523e+00, 9.7979e+00,\n",
      "        3.9617e+00, 7.9761e+00, 1.0336e+01, 3.9350e+00, 1.0497e+01, 7.7299e+00,\n",
      "        4.5418e+00, 4.7727e+00, 3.7862e+00, 5.6849e+00, 8.9757e+00, 6.3227e+00,\n",
      "        6.0544e+00, 5.0624e+00, 9.3569e+00, 8.8488e+00, 3.5819e+00, 6.7183e+00,\n",
      "        3.1087e+00, 8.0798e+00, 4.6827e+00, 6.3036e+00, 7.8911e+00, 8.6943e+00,\n",
      "        5.6009e+00, 7.0382e+00, 5.2915e+00, 5.2025e+00, 8.6922e+00, 5.4305e+00,\n",
      "        8.0498e+00, 3.6808e+00, 3.7519e+00, 1.0194e+01, 9.2235e+00, 6.0132e+00,\n",
      "        6.5676e+00, 8.3911e+00, 5.1833e+00, 3.8679e+00, 7.7752e+00, 5.5394e+00,\n",
      "        9.5489e+00, 8.5529e+00, 4.5163e+00, 8.5944e+00, 4.7835e+00, 8.6575e+00,\n",
      "        9.3942e+00, 5.6895e+00, 6.5135e+00, 9.4706e+00, 4.6458e+00, 6.9426e+00,\n",
      "        3.7437e+00, 3.9939e+00, 4.0432e+00, 6.9830e+00, 6.3321e+00, 7.1658e+00,\n",
      "        6.6166e+00, 4.7190e+00, 3.3701e+00, 6.7666e+00, 3.1320e+00, 8.8562e+00,\n",
      "        5.3791e+00, 8.0590e+00, 6.5740e+00, 9.0856e+00, 5.2626e+00, 1.0195e+01,\n",
      "        5.4515e+00, 5.1587e+00, 8.0972e+00, 7.5084e+00, 6.1303e+00, 5.2670e+00,\n",
      "        3.4787e+00, 1.1484e+01, 7.1376e+00, 5.8718e+00, 7.3861e+00, 4.9590e+00,\n",
      "        8.0897e+00, 9.1918e+00, 7.7839e+00, 3.4791e+00, 3.7906e+00, 3.3480e+00,\n",
      "        7.5775e+00, 7.1918e+00, 3.2097e+00, 4.1511e+00, 8.5377e+00, 7.3721e+00,\n",
      "        3.0120e+00, 4.6129e+00, 6.2192e+00, 3.4422e+00, 6.0563e+00, 5.9516e+00,\n",
      "        4.0190e+00, 3.5407e+00, 5.6068e+00, 4.2258e+00, 1.1286e+01, 3.2316e+00,\n",
      "        5.5592e+00, 7.3136e+00, 7.2384e+00, 1.0512e+01, 7.8267e+00, 5.6981e+00,\n",
      "        8.5891e+00, 4.9513e+00, 8.0835e+00, 9.5240e+00, 7.4842e+00, 5.6330e+00,\n",
      "        3.1683e+00, 3.3560e+00, 5.4091e+00, 3.5521e+00, 9.6214e+00, 5.0401e+00,\n",
      "        6.9297e+00, 3.0719e+00, 3.0884e+00, 3.8987e+00, 4.3794e+00, 6.9996e+00,\n",
      "        4.6855e+00, 3.1863e+00, 6.2594e+00, 5.6830e+00, 7.7929e+00, 7.0382e+00,\n",
      "        4.9504e+00, 5.8923e+00, 7.7708e+00, 6.6091e+00, 7.8523e+00, 1.0380e+01,\n",
      "        1.2756e+01, 5.4537e+00, 4.7133e+00, 6.3735e+00, 8.2298e+00, 3.2178e+00,\n",
      "        1.0363e+01, 4.9310e+00, 3.9457e+00, 1.0580e+01, 6.4487e+00, 6.5425e+00,\n",
      "        5.4107e+00, 5.9554e+00, 5.4179e+00, 3.1504e+00, 8.1255e+00, 8.8501e+00,\n",
      "        8.6074e+00, 7.7413e+00, 3.7534e+00, 7.0345e+00, 6.4847e+00, 8.9396e+00,\n",
      "        5.8023e+00, 1.0406e+01, 8.0463e+00, 4.5356e+00, 7.3838e+00, 7.8119e+00,\n",
      "        5.1363e+00, 5.3530e+00, 5.3543e+00, 9.7198e+00, 5.0174e+00, 5.7285e+00,\n",
      "        7.0409e+00, 4.1899e+00, 8.6277e+00, 3.3583e+00, 5.7691e+00, 3.8901e+00,\n",
      "        1.0084e+01, 5.8236e+00, 5.8059e+00, 9.5688e+00, 1.0034e+01, 5.0139e+00,\n",
      "        7.2634e+00, 5.4524e+00, 6.9710e+00, 4.1522e+00, 2.7732e+00, 8.6479e+00,\n",
      "        8.1868e+00, 6.6864e+00, 4.0525e+00, 8.6515e+00, 5.7811e+00, 4.7966e+00,\n",
      "        7.4557e+00, 7.3993e+00, 3.8278e+00, 8.2424e+00, 3.9622e+00, 4.7546e+00,\n",
      "        9.1122e+00, 5.8771e+00, 4.5526e+00, 7.7826e+00, 9.2731e+00, 7.8702e+00,\n",
      "        5.3535e+00, 5.4416e+00, 7.5235e+00, 8.3700e+00, 7.2439e+00, 6.0966e+00,\n",
      "        8.6692e+00, 6.8212e+00, 7.0035e+00, 8.4297e+00, 3.0159e+00, 5.8750e+00,\n",
      "        8.0102e+00, 9.3814e+00, 8.5180e+00, 9.8078e+00, 6.1492e+00, 7.0556e+00,\n",
      "        3.8735e+00, 4.8720e+00, 4.4385e+00, 3.8542e+00, 3.6660e+00, 3.8003e+00,\n",
      "        3.2300e+00, 8.9450e+00, 8.2184e+00, 5.6740e+00, 8.0082e+00, 8.2053e+00,\n",
      "        1.1351e+01, 7.5063e+00, 5.1269e+00, 7.3183e+00, 5.0783e+00, 7.8631e+00,\n",
      "        8.6588e+00, 6.8184e+00, 6.2737e+00, 4.9090e+00, 9.1254e+00, 8.5782e+00,\n",
      "        3.7535e+00, 1.1084e+01, 9.1094e+00, 2.9868e+00, 8.3425e+00, 3.7011e+00,\n",
      "        3.3289e+00, 3.2686e+00, 3.3283e+00, 6.4590e+00, 9.0846e+00, 8.8574e+00,\n",
      "        7.0781e+00, 8.1532e+00, 6.1914e+00, 7.8346e+00, 3.2493e+00, 5.4511e+00,\n",
      "        9.3460e+00, 2.9453e+00, 7.5686e+00, 3.1738e+00, 8.8898e+00, 9.8755e+00,\n",
      "        7.6629e+00, 5.4953e+00, 9.7714e+00, 4.2466e+00, 6.6470e+00, 4.2362e+00,\n",
      "        7.6873e+00, 8.5791e+00, 7.9667e+00, 8.3475e+00, 6.5838e+00, 7.8900e+00,\n",
      "        3.4000e+00, 6.8933e+00, 4.5443e+00, 3.9548e+00, 1.0438e+01, 4.5279e+00,\n",
      "        4.1988e+00, 4.4367e+00, 9.4230e+00, 3.3611e+00, 1.1362e+01, 6.8162e+00,\n",
      "        6.0071e+00, 3.4555e+00, 5.6734e+00, 5.3026e+00, 5.3561e+00, 7.4023e+00,\n",
      "        3.0105e+00, 1.1883e+01, 6.5486e+00, 4.5684e+00, 6.6447e+00, 3.7209e+00,\n",
      "        7.5517e+00, 2.9322e+00, 6.9778e+00, 3.5857e+00, 7.1919e+00, 9.0372e+00,\n",
      "        8.9601e+00, 4.6741e+00, 4.9488e+00, 3.4248e+00, 5.2198e+00, 7.5679e+00,\n",
      "        6.4987e+00, 6.7370e+00, 3.5667e+00, 7.6972e+00, 6.5556e+00, 7.2954e+00,\n",
      "        1.0580e+01, 9.1449e+00, 3.7958e+00, 3.3113e+00, 7.9464e+00, 3.4591e+00,\n",
      "        6.6797e+00, 9.3859e+00, 3.5483e+00, 9.0908e+00, 7.9626e+00, 1.0216e+01,\n",
      "        7.7245e+00, 6.5630e+00, 3.7891e+00, 3.2757e+00, 7.2467e+00, 5.6145e+00,\n",
      "        7.5365e+00, 1.1402e+01, 1.3002e+01, 7.3544e+00, 3.4243e+00, 4.9644e+00,\n",
      "        6.3161e+00, 6.9674e+00, 5.4116e+00, 4.1133e+00, 7.0385e+00, 9.7940e+00,\n",
      "        2.9155e+00, 5.6429e+00, 4.9909e+00, 6.6497e+00, 8.7693e+00, 3.1762e+00,\n",
      "        8.0741e+00, 9.7528e+00, 2.9227e+00, 3.7020e+00, 6.0665e+00, 4.2494e+00,\n",
      "        9.7000e+00, 9.3991e+00, 7.6235e+00, 3.3766e+00, 4.0203e+00, 8.6022e+00,\n",
      "        3.8176e+00, 5.1802e+00, 5.5316e+00, 5.4432e+00, 9.9317e+00, 4.0665e+00,\n",
      "        4.1550e+00, 9.0631e+00, 5.5023e+00, 3.6911e+00, 3.1138e+00, 4.2985e+00,\n",
      "        4.7644e+00, 7.3784e+00, 3.4842e+00, 4.6160e+00, 8.5060e+00, 3.3142e+00,\n",
      "        8.9135e+00, 4.0429e+00, 8.6345e+00, 5.3481e+00, 9.5863e+00, 8.7544e+00,\n",
      "        7.9908e+00, 5.7175e+00, 8.3853e+00, 4.2286e+00, 3.1138e+00, 8.2064e+00,\n",
      "        3.5675e+00, 4.3675e+00, 7.7319e+00, 7.1771e+00, 9.6834e+00, 8.6295e+00,\n",
      "        7.8344e+00, 4.4064e+00, 4.9193e+00, 5.6670e+00, 9.6474e+00, 4.4878e+00,\n",
      "        9.1300e+00, 3.6377e+00, 9.3860e+00, 3.6618e+00, 9.8020e+00, 6.6160e+00,\n",
      "        4.5722e+00, 9.6742e+00, 5.4091e+00, 6.5519e+00, 5.6769e+00, 3.4382e+00,\n",
      "        2.9444e+00, 7.2198e+00, 5.2697e+00, 8.7787e+00, 7.8766e+00, 9.3956e+00,\n",
      "        3.5478e+00, 3.4882e+00, 3.9085e+00, 7.3057e+00, 4.1144e+00, 3.9755e+00,\n",
      "        7.5025e+00, 8.6008e+00, 6.6098e+00, 3.5554e+00, 1.0626e+01, 3.1488e+00,\n",
      "        7.9043e+00, 3.2798e+00, 4.0173e+00, 3.5013e+00, 6.6540e+00, 8.2762e+00,\n",
      "        8.2976e+00, 3.4837e+00, 6.2126e+00, 8.0384e+00, 9.8715e+00, 4.9694e+00,\n",
      "        8.5461e+00, 4.2902e+00, 5.2908e+00, 4.1534e+00, 7.2352e+00, 3.7482e+00,\n",
      "        8.5269e+00, 9.2938e+00, 5.5356e+00, 8.1110e+00, 4.9919e+00, 8.2987e+00,\n",
      "        6.3344e+00, 4.8938e+00, 3.7678e+00, 6.1107e+00, 6.9802e+00, 3.3567e+00,\n",
      "        3.0728e+00, 5.5102e+00, 4.0306e+00, 8.6632e+00, 3.9461e+00, 5.6183e+00,\n",
      "        4.0018e+00, 5.8868e+00, 5.8519e+00, 1.1038e+01, 5.8544e+00, 4.9120e+00,\n",
      "        6.9153e+00, 3.9614e+00, 8.3944e+00, 4.7480e+00, 5.9777e+00, 5.8931e+00,\n",
      "        3.5970e+00, 3.1689e+00, 8.0881e+00, 8.7403e+00, 7.0849e+00, 5.7249e+00,\n",
      "        7.3308e+00, 6.9074e+00, 3.9083e+00, 5.4035e+00, 1.0193e+01, 3.3567e+00,\n",
      "        6.4593e+00, 4.9002e+00, 3.8470e+00, 4.9572e+00, 8.8235e+00, 5.6614e+00,\n",
      "        8.0598e+00, 5.1703e+00, 3.3257e+00, 6.4650e+00, 9.4115e+00, 8.3085e+00,\n",
      "        9.1309e+00, 5.3749e+00, 6.9066e+00, 7.3838e+00, 3.4842e+00, 1.0632e+01,\n",
      "        7.8035e+00, 7.8717e+00, 3.7685e+00, 7.5363e+00, 3.3008e+00, 3.5080e+00,\n",
      "        6.2876e+00, 9.5707e+00, 6.0422e+00, 7.9723e+00, 7.4505e+00, 8.9938e+00,\n",
      "        1.0643e+01, 4.9866e+00, 3.6987e+00, 3.3626e+00, 7.1359e+00, 8.9976e+00,\n",
      "        4.4603e+00, 4.9922e+00, 6.1043e+00, 4.9222e+00, 7.9808e+00, 8.5458e+00,\n",
      "        4.1839e+00, 9.6521e+00, 4.0170e+00, 6.5732e+00, 5.4708e+00, 3.2398e+00,\n",
      "        6.0747e+00, 4.9396e+00, 8.5601e+00, 7.1609e+00, 5.9334e+00, 5.5488e+00,\n",
      "        8.8761e+00, 7.5401e+00, 6.9470e+00, 3.2323e+00, 7.7317e+00, 5.0165e+00,\n",
      "        6.2207e+00, 6.3177e+00, 7.0321e+00, 7.0719e+00, 3.4182e+00, 9.1842e+00,\n",
      "        4.0839e+00, 3.4423e+00, 6.5856e+00, 3.4220e+00, 3.8639e+00, 7.2523e+00,\n",
      "        9.0686e+00, 3.2625e+00, 8.0228e+00, 8.0859e+00, 4.4613e+00, 7.2692e+00,\n",
      "        6.3120e+00, 8.6051e+00, 3.4371e+00, 8.1944e+00, 4.9294e+00, 3.9670e+00,\n",
      "        7.2341e+00, 6.6672e+00, 5.5629e+00, 5.8174e+00, 5.9722e+00, 7.5646e+00,\n",
      "        3.6566e+00, 6.4264e+00, 7.0286e+00, 4.2823e+00, 3.3507e+00, 6.1630e+00,\n",
      "        6.6233e+00, 7.9552e+00, 4.6428e+00, 3.8858e+00, 9.7319e+00, 5.5508e+00,\n",
      "        7.3710e+00, 3.6222e+00, 1.1745e+01, 5.1334e+00, 8.7392e+00, 6.3503e+00,\n",
      "        7.0786e+00, 3.3529e+00, 6.2688e+00, 8.8914e+00, 3.5576e+00, 4.2799e+00,\n",
      "        1.0305e+01, 4.6928e+00, 3.8525e+00, 3.9030e+00, 4.9838e+00, 3.4016e+00,\n",
      "        3.8199e+00, 7.4299e+00, 4.3648e+00, 1.0329e+01, 8.3794e+00, 9.5700e+00,\n",
      "        9.2923e+00, 3.1691e+00, 7.8062e+00, 9.8768e+00, 4.5749e+00, 7.9668e+00,\n",
      "        3.9895e+00, 7.8825e+00, 4.4768e+00, 3.9744e+00, 9.8713e+00, 3.4107e+00,\n",
      "        7.7165e+00, 5.4271e+00, 5.7268e+00, 9.1966e+00, 9.3337e+00, 4.4537e+00,\n",
      "        5.9488e+00, 6.4124e+00, 5.7915e+00, 6.4756e+00, 3.7836e+00, 3.8969e+00,\n",
      "        4.9854e+00, 3.2755e+00, 6.7285e+00, 9.0393e+00, 6.7707e+00, 7.0138e+00,\n",
      "        7.6408e+00, 3.8995e+00, 7.6685e+00, 8.1655e+00, 6.6703e+00, 4.8812e+00,\n",
      "        3.6304e+00, 5.9016e+00, 7.0629e+00, 8.4321e+00, 6.7382e+00, 7.8248e+00,\n",
      "        3.9680e+00, 3.0185e+00, 6.8003e+00, 3.6088e+00, 5.3620e+00, 7.5160e+00,\n",
      "        3.5589e+00, 3.8852e+00, 8.9565e+00, 4.4865e+00, 4.4237e+00, 4.3102e+00,\n",
      "        8.3266e+00, 9.5601e+00, 7.2798e+00, 8.3376e+00, 8.1591e+00, 3.5793e+00,\n",
      "        5.6442e+00, 6.6767e+00, 3.5733e+00, 5.9275e+00, 9.5475e+00, 8.4704e+00,\n",
      "        9.8181e+00, 3.9459e+00, 8.3105e+00, 9.0326e+00, 1.1969e+01, 3.4203e+00,\n",
      "        3.1448e+00, 8.8994e+00, 4.4566e+00, 3.9582e+00, 7.1626e+00, 9.6808e+00,\n",
      "        6.3188e+00, 5.7239e+00, 7.2855e+00, 7.4175e+00, 7.7026e+00, 3.4837e+00,\n",
      "        7.7782e+00, 8.9690e+00, 7.2644e+00, 3.9075e+00, 4.6317e+00, 6.9228e+00,\n",
      "        1.2188e+01, 3.3633e+00, 8.9436e+00, 7.6205e+00])\n",
      "torch.Size([20000])\n",
      "torch.Size([20000, 910])\n",
      "tensor([ 10.0000, 351.0000,   7.0129,   3.9810,   7.9036,   5.4686,   4.2308,\n",
      "          2.9414,   6.4587,   6.8352,   6.2356,   7.0237,   7.3349,   5.3529,\n",
      "          8.5231,   6.3567,   3.9769,   3.3935,   7.2448,   6.4915,   7.8003,\n",
      "          6.9384,   6.5620,   5.8181,   7.9801,   4.6208,   3.7930,   8.8801,\n",
      "          7.0513,   2.6956,   9.2094,   7.1193,   4.7488,   7.6068,   4.5451,\n",
      "          7.6742,   3.3366,   5.4680,   6.6340,   5.0702,   9.4375,   6.5079,\n",
      "          5.3839,   7.0963,   9.1712,   5.5484,   3.4887,   3.2230,   8.0802,\n",
      "          5.6019,   6.9643,   4.7313,   6.6446,   3.0560,   4.5647,   8.9449,\n",
      "          5.3847,   9.0442,   4.3796,   8.6705,   3.2402,   9.3238,   5.8029,\n",
      "          8.4275,   4.9719,   7.8999,   3.1254,   4.9580,   4.9177,   4.9658,\n",
      "          6.7970,   4.2089,   6.2459,   7.2770,   4.9054,   3.4458,   4.2460,\n",
      "          7.7669,   6.8401,   3.6052,   2.9407,  10.7375,   6.0809,   7.6770,\n",
      "          3.4269,   8.0502,   4.8651,   4.4618,   8.6958,   8.7086,   3.9640,\n",
      "          9.7430,   8.9974,   5.7763,   6.7964,   4.6331,   5.9521,   6.1766,\n",
      "          6.8887,   8.1939,   4.6865,   7.8803,   3.7349,   6.4419,   4.6870,\n",
      "          4.4076,   6.3777,   6.4858,   3.5847,   3.0901,   7.4817,  10.9561,\n",
      "          7.5180,   7.8373,   3.5378,   3.7201,   6.3005,   2.6852,   3.5973,\n",
      "          3.1096,   8.5372,   5.4125,   5.1161,   3.0533,   7.7589,   3.3351,\n",
      "          3.0309,   9.1242,   8.0844,   3.4102,   5.8168,   3.4499,   9.3224,\n",
      "          9.8286,   7.7671,   5.3187,   7.9564,   7.6091,   5.8000,   3.9279,\n",
      "          6.8183,   3.6534,   3.0266,   2.8343,   7.5395,   5.0919,   8.6710,\n",
      "         10.6861,   6.3555,   6.1654,  11.7416,   7.4876,   8.9051,   5.8729,\n",
      "          7.4344,   6.4030,   6.4523,   6.0807,   7.0168,   7.4345,   3.2752,\n",
      "         11.6838,   7.0596,  10.7347,   8.4493,  10.1465,   5.0417,   7.1524,\n",
      "          3.7271,   8.5648,   3.0968,   5.6394,   8.9562,   8.9896,   3.7884,\n",
      "          8.6672,   9.9490,   3.2280,  10.7498,   6.7885,   4.9254,   8.1572,\n",
      "          7.0786,   5.5362,   8.9719,   3.4343,   5.7809,   3.8265,   7.9964,\n",
      "          7.8816,   4.0464,   6.8422,   3.6139,   8.5046,   6.0057,   6.6420,\n",
      "          9.9660,   7.9093,   6.5723,   7.6734,   7.7742,   6.3798,   9.3272,\n",
      "          5.4792,   7.9915,   3.6197,   3.2080,   7.6548,   8.3186,   5.7580,\n",
      "          5.7042,   6.5743,   6.2043,   3.5912,   7.3639,   4.8962,   9.1344,\n",
      "          9.7047,   4.2694,   9.4788,   5.5296,   8.1593,   5.6466,   5.0409,\n",
      "          4.2682,   8.9275,   4.5141,   6.9089,   3.3305,   4.2320,   3.3750,\n",
      "          6.6951,   6.3051,   8.5325,   4.8036,   3.5055,   3.0151,   6.4417,\n",
      "          5.8046,   6.6361,   4.3699,   6.4133,   6.8682,  10.0764,   4.9556,\n",
      "          9.0137,   4.5552,   3.2440,   8.8738,   9.5263,   6.4854,   4.9253,\n",
      "          5.8346,  11.2823,   6.4889,   4.6868,   7.6249,   7.5302,   3.3890,\n",
      "          9.4487,   4.5264,   6.6798,   3.7450,   4.0789,   5.3450,   7.3630,\n",
      "          3.3619,   4.8749,   8.7753,   6.2480,   3.1653,   4.6049,   7.2764,\n",
      "          5.9335,   5.0193,   6.6352,   5.2741,   7.2356,   5.9486,   7.9943,\n",
      "          7.8563,   2.8993,   4.5194,   4.3868,   5.9853,   9.9656,   7.9408,\n",
      "          5.1521,   8.0344,   5.3679,   7.3470,   7.7808,   6.1937,   4.3761,\n",
      "          3.3399,   2.9506,   4.8270,   3.5258,   7.7674,   6.4510,   6.9980,\n",
      "          2.9341,   3.3892,   7.2081,   6.3905,   6.7515,   4.2878,   2.8437,\n",
      "          3.7754,   4.6679,   7.7589,   7.2923,   4.1675,   5.8238,   7.5172,\n",
      "          8.9533,   8.9065,   9.6543,  12.8490,   5.2875,   4.0974,   5.4939,\n",
      "          8.2006,   3.0390,   9.2259,   5.6818,   4.0177,  10.5826,   3.2574,\n",
      "          6.1898,   3.4660,   5.5864,   6.8348,   2.9945,   8.3798,   9.9843,\n",
      "          8.5664,   7.4418,   6.3578,   6.7857,   8.2798,   9.0351,   5.1856,\n",
      "         10.8209,   6.7392,   6.2710,   6.1941,   7.8708,   3.5857,   3.9760,\n",
      "          5.5032,   8.9388,   6.1293,   5.7895,   6.5475,   4.0826,   9.2553,\n",
      "          2.9408,   6.3575,   6.8226,   8.7501,   4.3250,   5.8244,   9.9391,\n",
      "          8.6068,   4.9488,   7.0789,   5.7055,   8.0590,   4.3041,   2.4552,\n",
      "          9.4992,   8.1256,   5.9096,   5.1540,   8.5488,   5.8947,   3.6931,\n",
      "          6.7835,   7.7939,   4.6660,   9.1009,   4.8694,   4.8629,   9.8369,\n",
      "          4.8936,   4.4941,   8.9034,   9.8184,   7.8131,   5.8329,   4.1433,\n",
      "          7.1590,   6.1332,   7.4776,   2.9089,   7.7097,   7.7672,   5.1944,\n",
      "          9.8643,   2.8993,   5.3251,   6.5650,   8.9031,   9.5307,  10.0418,\n",
      "          4.5202,   8.3783,   4.7596,   7.7180,   5.8919,   8.0566,   3.5753,\n",
      "          3.3180,   3.0355,   8.2037,   6.7333,   5.8866,   6.7845,   8.2192,\n",
      "          9.2172,   7.1344,   4.7950,   5.8601,   3.7411,   6.4011,   6.5753,\n",
      "          8.4404,   4.1551,   4.6235,   8.7991,   7.3702,   3.4581,  11.2670,\n",
      "          9.4727,   3.4026,   7.9605,   4.5416,   3.4849,   3.0785,   4.4611,\n",
      "          5.1556,   7.8800,   8.2257,   7.4473,   8.3592,   7.2792,   7.7089,\n",
      "          5.8985,   5.8094,   9.6586,   2.8635,   9.2724,   5.2664,   6.4840,\n",
      "          8.7150,   7.7224,   9.3238,   9.8018,   3.3382,   7.7207,   6.5750,\n",
      "          7.6279,   9.9753,   8.5664,   8.0893,   5.8758,   8.6437,   3.7328,\n",
      "          6.9343,   3.3223,   4.7221,  10.6013,   4.9590,   6.2567,   4.2717,\n",
      "          8.1987,   4.0124,  11.4312,   7.1356,   6.0519,   3.2700,   6.2076,\n",
      "          5.1110,   4.2416,   7.1249,   7.3060,  11.3824,   6.6418,   4.5054,\n",
      "          5.2919,   3.8369,   5.3616,   2.9302,   9.7805,   3.3351,   5.4137,\n",
      "          9.3483,   7.5183,   4.9994,   3.5566,   3.4045,   8.6693,   6.3635,\n",
      "          6.6061,   3.9134,   7.0242,   8.9450,   7.1857,   8.1367,   8.5030,\n",
      "          8.4632,   4.4178,   7.7060,   7.2271,   3.7650,   5.8917,   8.1852,\n",
      "          4.8464,   8.0390,   6.7521,   8.9616,   7.6287,   6.6367,   5.5397,\n",
      "          3.3207,   7.6317,   4.1893,   6.7764,   4.7578,  12.3562,   4.8245,\n",
      "          3.3332,   4.5049,   5.2459,   7.0437,   5.6083,   4.0787,   6.4524,\n",
      "         10.3043,   4.3860,   5.3563,   3.3124,   6.0311,   9.1548,   3.4845,\n",
      "          8.4481,   8.8393,   2.8864,   5.7748,   3.8456,   3.7010,   9.7361,\n",
      "         10.2571,   7.7764,   6.0090,   3.8371,   8.3326,   3.1255,   4.6521,\n",
      "          7.5197,   4.4234,   9.7253,   3.3587,   3.2908,   8.6079,   5.1032,\n",
      "          3.4138,   4.5713,   3.9058,   3.9256,   6.4846,   9.5492,   5.2260,\n",
      "          7.8995,   3.3998,   9.9084,   7.9234,   9.1097,   9.1261,   9.7426,\n",
      "          7.1039,   7.6123,   5.8183,   5.7453,   3.4732,   3.2097,   8.2291,\n",
      "          4.8090,   3.5666,   7.2875,   6.9063,   8.2774,   7.1989,   6.3697,\n",
      "          5.2987,   4.1927,   5.6366,   9.2354,   4.7766,   9.4565,   3.7686,\n",
      "          9.1644,   4.1638,   7.0980,   5.0077,   3.8764,   7.2100,   3.7743,\n",
      "          3.4512,   4.8841,   3.3399,   2.9960,   7.2977,   6.3248,   8.5894,\n",
      "          6.7452,   9.6399,   9.0779,   3.7258,   3.8199,   6.9307,   6.5870,\n",
      "          3.7315,   7.2278,   6.8092,   6.0066,   4.3011,  10.7520,   3.1995,\n",
      "          5.7315,   4.6954,   4.1153,   8.8930,   5.8058,   7.3707,   5.7909,\n",
      "          6.5489,   6.3784,   7.1918,   7.8522,   5.4088,   8.5217,   4.3930,\n",
      "          4.3242,   4.6144,   5.2846,   3.5900,  10.2440,   8.9051,   6.2537,\n",
      "          6.7168,   5.9828,   5.3370,   4.8264,   3.1706,   6.0117,   6.0646,\n",
      "          5.6911,   4.5567,   5.8887,   5.0055,   4.1098,   5.2828,   3.9840,\n",
      "          5.3771,   6.0966,   7.3781,   6.0061,  10.1219,   4.9990,   6.6928,\n",
      "          6.7514,   4.2923,   7.2252,   6.5022,   4.5454,   5.5457,   3.9261,\n",
      "          3.1196,   7.3182,   7.7566,   7.1055,   5.3352,   6.9752,   6.0076,\n",
      "          3.4078,   3.3678,  10.8303,   7.0233,   5.8911,   6.4504,   4.0221,\n",
      "          7.4800,   8.5292,   3.3523,   7.7858,   6.7912,   3.6654,   6.6636,\n",
      "          9.2722,   9.2979,   8.5013,   4.5404,   8.4490,   5.4328,   3.1177,\n",
      "          9.4504,   6.4976,   6.7462,   3.4199,   7.2566,   3.1307,   4.2847,\n",
      "          8.5701,   7.8308,   7.8257,  10.3084,   9.3626,  10.2057,  10.0855,\n",
      "          5.3878,   4.1465,   7.0526,   7.6809,   6.4925,   4.3698,   6.9772,\n",
      "          6.0640,   5.0216,   7.5528,   9.2425,   4.5063,   9.8615,   3.8561,\n",
      "          5.2415,   4.1806,   6.5563,   6.2081,   4.2358,   7.6259,   6.9964,\n",
      "          5.2825,   5.4226,   9.5770,  10.7445,   6.7670,   4.0342,   7.0773,\n",
      "          5.0401,   3.4583,   6.3510,   2.9256,   6.3382,   4.5525,   7.0157,\n",
      "          3.3681,   6.6139,   7.5660,   3.8800,   3.6032,   5.8690,   9.0895,\n",
      "          3.9827,   8.9812,   7.8947,   3.7503,   5.6767,   6.9589,   5.4986,\n",
      "          3.4078,   6.9139,   6.0698,   4.1037,   6.0995,   5.7502,   6.1192,\n",
      "          6.9533,   7.1393,   7.1178,   4.0045,   5.7630,   7.3379,   4.2744,\n",
      "          3.9932,   6.9944,   6.3145,   2.7597,   3.5466,   4.1541,   7.6506,\n",
      "          4.4833,   8.1575,   4.5561,  12.0599,   4.6988,   9.0324,   5.4900,\n",
      "          6.9665,   3.3799,   4.2384,   8.1207,   7.2439,   4.1703,   9.5634,\n",
      "          3.7248,   4.1425,   6.2390,   3.4872,   7.8979,   6.2936,   6.1218,\n",
      "          7.1684,   9.4070,   5.9297,   9.5843,   6.3523,   3.7204,   6.4976,\n",
      "          9.5163,   4.2496,   7.3229,   4.8290,   7.1377,   6.7494,   6.2669,\n",
      "          8.1154,   3.9053,   7.6927,   6.0025,   4.4571,   7.9366,   8.9700,\n",
      "          3.6398,   5.6846,   6.5781,   5.9751,   6.9095,   3.3612,   3.7591,\n",
      "          6.3626,   5.5083,   2.9164,   7.4774,   5.7630,   8.0735,   6.3215,\n",
      "          3.5385,   7.2655,   9.0091,   6.5546,   8.8144,   6.9935,   9.1082,\n",
      "          6.3188,   7.1041,   7.4251,   7.7661,   4.2434,   3.0391,   6.9246,\n",
      "          4.2227,   3.6507,   6.8668,   4.4225,   3.7022,   7.8882,   4.3163,\n",
      "          3.5562,   4.1711,   9.0792,   8.9962,   5.6515,   8.6136,   7.3118,\n",
      "          3.6832,   6.3633,   7.5443,   3.5492,   8.1884,   8.2249,  10.5149,\n",
      "          6.4049,   5.3441,   7.0664,   3.5812,   2.8753,   3.3252,  11.0232,\n",
      "          8.0240,   6.8099,   5.4569,   7.7285,   9.2195,   6.6190,   5.6404,\n",
      "         10.2122,   8.1831,   7.9333,   4.4130,   7.5336,   8.8626,   5.8228,\n",
      "          3.6605,   8.3688,   5.8049,  12.8666,   4.0837,   3.0183,   5.1311])\n",
      "torch.Size([20000])\n",
      "torch.Size([20000, 910])\n",
      "tensor([2.0000e+00, 9.0985e+04, 5.2468e+00, 3.8203e+00, 7.0574e+00, 5.5568e+00,\n",
      "        5.3686e+00, 3.0986e+00, 5.6761e+00, 8.5616e+00, 4.6759e+00, 7.0862e+00,\n",
      "        6.6504e+00, 6.0248e+00, 7.9951e+00, 7.1960e+00, 4.5893e+00, 3.4095e+00,\n",
      "        6.6906e+00, 6.8650e+00, 7.6806e+00, 7.8019e+00, 6.6083e+00, 5.0803e+00,\n",
      "        8.5028e+00, 5.6821e+00, 5.1519e+00, 7.6592e+00, 5.3896e+00, 2.7310e+00,\n",
      "        5.0718e+00, 5.7640e+00, 4.4446e+00, 5.5875e+00, 4.9279e+00, 6.4690e+00,\n",
      "        3.0920e+00, 4.9365e+00, 8.1828e+00, 5.1591e+00, 7.6883e+00, 6.7556e+00,\n",
      "        8.7675e+00, 7.8500e+00, 1.1239e+01, 6.7928e+00, 3.4006e+00, 3.7404e+00,\n",
      "        6.9566e+00, 7.4924e+00, 7.1011e+00, 4.6419e+00, 6.6042e+00, 2.9925e+00,\n",
      "        7.5977e+00, 6.5439e+00, 5.4403e+00, 9.4659e+00, 5.8661e+00, 9.4122e+00,\n",
      "        2.7935e+00, 9.8703e+00, 5.0782e+00, 6.0342e+00, 5.2383e+00, 8.5444e+00,\n",
      "        3.3880e+00, 6.6089e+00, 3.9918e+00, 3.2023e+00, 6.6917e+00, 5.2216e+00,\n",
      "        5.2966e+00, 7.2142e+00, 4.3156e+00, 4.5461e+00, 4.5658e+00, 7.4451e+00,\n",
      "        5.8429e+00, 3.5138e+00, 4.5468e+00, 1.0605e+01, 6.5021e+00, 7.1968e+00,\n",
      "        3.1236e+00, 8.7654e+00, 5.0999e+00, 5.1854e+00, 7.3689e+00, 8.7119e+00,\n",
      "        4.5910e+00, 9.0611e+00, 1.0109e+01, 6.5545e+00, 6.9693e+00, 6.0006e+00,\n",
      "        5.4818e+00, 5.3807e+00, 5.4381e+00, 9.1009e+00, 5.7564e+00, 9.5757e+00,\n",
      "        2.5631e+00, 6.6072e+00, 4.4544e+00, 4.6369e+00, 6.6584e+00, 7.4041e+00,\n",
      "        3.3407e+00, 3.0193e+00, 4.6471e+00, 1.0169e+01, 7.5872e+00, 5.8987e+00,\n",
      "        3.6665e+00, 4.1431e+00, 6.4864e+00, 2.7199e+00, 3.4642e+00, 3.0790e+00,\n",
      "        7.7583e+00, 5.8866e+00, 6.5362e+00, 3.2504e+00, 9.2173e+00, 3.6585e+00,\n",
      "        3.1988e+00, 8.5221e+00, 8.2731e+00, 3.8532e+00, 4.8022e+00, 3.6439e+00,\n",
      "        1.0935e+01, 8.0311e+00, 7.7913e+00, 4.5402e+00, 8.1012e+00, 7.9212e+00,\n",
      "        3.8407e+00, 3.7335e+00, 4.9638e+00, 4.2604e+00, 3.6005e+00, 2.8144e+00,\n",
      "        8.0206e+00, 6.4651e+00, 8.3159e+00, 1.0080e+01, 7.8743e+00, 4.0691e+00,\n",
      "        1.1740e+01, 7.9402e+00, 8.9261e+00, 5.4996e+00, 7.3240e+00, 6.5072e+00,\n",
      "        6.8937e+00, 6.4240e+00, 6.0351e+00, 6.5420e+00, 3.3728e+00, 3.4072e+00,\n",
      "        7.8001e+00, 1.0342e+01, 8.0005e+00, 7.6132e+00, 4.4378e+00, 7.4117e+00,\n",
      "        3.7099e+00, 8.4993e+00, 3.3434e+00, 6.3167e+00, 8.9073e+00, 1.0760e+01,\n",
      "        3.3704e+00, 8.0722e+00, 9.9143e+00, 2.9858e+00, 1.1054e+01, 7.2226e+00,\n",
      "        4.0236e+00, 7.7638e+00, 8.8652e+00, 4.8147e+00, 8.3356e+00, 6.1913e+00,\n",
      "        5.5323e+00, 5.3074e+00, 1.0635e+01, 8.3874e+00, 4.3197e+00, 7.3936e+00,\n",
      "        3.8904e+00, 7.7307e+00, 5.5206e+00, 6.8335e+00, 8.7278e+00, 8.7923e+00,\n",
      "        7.5482e+00, 6.3315e+00, 7.6907e+00, 6.5191e+00, 8.1112e+00, 6.0744e+00,\n",
      "        7.6293e+00, 3.2339e+00, 3.6320e+00, 7.3206e+00, 7.3969e+00, 5.5635e+00,\n",
      "        3.7294e+00, 6.8773e+00, 6.9312e+00, 3.9753e+00, 6.1324e+00, 4.2676e+00,\n",
      "        8.9605e+00, 8.6493e+00, 4.2889e+00, 9.2434e+00, 4.2076e+00, 6.8369e+00,\n",
      "        7.5808e+00, 5.8026e+00, 6.3999e+00, 8.6655e+00, 4.5546e+00, 7.5173e+00,\n",
      "        3.6579e+00, 3.8929e+00, 3.8135e+00, 7.0275e+00, 6.7500e+00, 6.1509e+00,\n",
      "        4.6282e+00, 5.6616e+00, 3.1346e+00, 6.0289e+00, 6.8392e+00, 1.0248e+01,\n",
      "        4.8734e+00, 8.2616e+00, 8.2552e+00, 9.0626e+00, 5.1248e+00, 1.0442e+01,\n",
      "        4.3501e+00, 4.0452e+00, 8.0550e+00, 8.0169e+00, 5.5064e+00, 4.8750e+00,\n",
      "        3.2423e+00, 9.3010e+00, 9.4527e+00, 4.3195e+00, 5.8444e+00, 7.7259e+00,\n",
      "        6.9407e+00, 9.4284e+00, 6.8794e+00, 6.2777e+00, 4.9284e+00, 4.0363e+00,\n",
      "        5.2891e+00, 6.8253e+00, 3.4332e+00, 4.6554e+00, 9.6543e+00, 5.4675e+00,\n",
      "        7.0246e+00, 8.9768e+00, 7.3552e+00, 7.0843e+00, 4.0019e+00, 7.0167e+00,\n",
      "        5.3832e+00, 7.0198e+00, 6.2728e+00, 7.9760e+00, 6.7009e+00, 3.1008e+00,\n",
      "        3.7517e+00, 8.4069e+00, 5.8823e+00, 7.8409e+00, 6.1451e+00, 4.5688e+00,\n",
      "        8.5194e+00, 5.0232e+00, 7.1055e+00, 7.4458e+00, 6.5165e+00, 4.4818e+00,\n",
      "        3.0320e+00, 3.1900e+00, 4.4637e+00, 4.5335e+00, 9.5023e+00, 6.0199e+00,\n",
      "        5.4011e+00, 3.2444e+00, 4.2720e+00, 6.1354e+00, 6.2758e+00, 8.9967e+00,\n",
      "        4.5214e+00, 3.1573e+00, 6.0574e+00, 4.0403e+00, 7.8152e+00, 8.4156e+00,\n",
      "        4.6008e+00, 5.8804e+00, 7.1358e+00, 6.0200e+00, 7.3131e+00, 8.1553e+00,\n",
      "        1.3175e+01, 7.3574e+00, 5.9725e+00, 7.8287e+00, 8.7458e+00, 3.1737e+00,\n",
      "        9.2534e+00, 4.9216e+00, 3.6631e+00, 1.0356e+01, 5.2272e+00, 5.3937e+00,\n",
      "        3.6740e+00, 5.0459e+00, 5.8647e+00, 2.9649e+00, 9.9867e+00, 8.0226e+00,\n",
      "        9.2221e+00, 8.9030e+00, 5.4759e+00, 6.5469e+00, 5.1895e+00, 7.2515e+00,\n",
      "        6.1461e+00, 9.4489e+00, 7.6987e+00, 4.7674e+00, 5.1444e+00, 6.8019e+00,\n",
      "        3.2297e+00, 4.3355e+00, 7.1683e+00, 9.6764e+00, 6.3787e+00, 6.8448e+00,\n",
      "        7.7832e+00, 4.1560e+00, 6.7557e+00, 4.0458e+00, 5.6040e+00, 7.9996e+00,\n",
      "        9.0161e+00, 4.8488e+00, 7.1434e+00, 1.0233e+01, 7.9647e+00, 7.0791e+00,\n",
      "        7.6245e+00, 5.8458e+00, 8.1646e+00, 3.7692e+00, 2.7783e+00, 9.1817e+00,\n",
      "        8.9870e+00, 5.7620e+00, 7.6733e+00, 9.4394e+00, 5.4063e+00, 6.1194e+00,\n",
      "        7.5908e+00, 7.9801e+00, 4.0513e+00, 1.1060e+01, 5.4489e+00, 4.8743e+00,\n",
      "        7.7133e+00, 5.4406e+00, 4.8402e+00, 8.9713e+00, 8.4065e+00, 6.4486e+00,\n",
      "        5.4452e+00, 5.0005e+00, 6.3390e+00, 6.6256e+00, 4.5155e+00, 1.1934e+01,\n",
      "        6.2630e+00, 7.4090e+00, 5.7174e+00, 8.5916e+00, 3.6143e+00, 4.0982e+00,\n",
      "        7.5280e+00, 8.0798e+00, 9.3423e+00, 1.0322e+01, 7.9871e+00, 7.7879e+00,\n",
      "        9.1359e+00, 9.9205e+00, 3.2464e+00, 1.0149e+01, 3.5187e+00, 3.8942e+00,\n",
      "        3.3527e+00, 1.0046e+01, 6.9938e+00, 5.5918e+00, 5.8392e+00, 5.8840e+00,\n",
      "        5.2717e+00, 7.1250e+00, 6.4935e+00, 7.5266e+00, 4.8432e+00, 6.4840e+00,\n",
      "        5.9703e+00, 6.5785e+00, 4.1218e+00, 4.8969e+00, 8.6725e+00, 7.6008e+00,\n",
      "        3.4753e+00, 9.0548e+00, 9.5105e+00, 7.3130e+00, 7.5978e+00, 4.2357e+00,\n",
      "        3.1635e+00, 3.2217e+00, 3.8252e+00, 5.6020e+00, 8.9569e+00, 1.0037e+01,\n",
      "        7.5993e+00, 8.7379e+00, 6.1046e+00, 6.2674e+00, 4.6313e+00, 5.7645e+00,\n",
      "        8.6861e+00, 5.3649e+00, 6.3887e+00, 6.9564e+00, 8.4904e+00, 9.0691e+00,\n",
      "        8.0351e+00, 8.1551e+00, 1.0352e+01, 4.6277e+00, 6.4871e+00, 3.5759e+00,\n",
      "        7.1810e+00, 8.2247e+00, 8.3666e+00, 7.2797e+00, 8.3372e+00, 9.5250e+00,\n",
      "        4.2348e+00, 6.9679e+00, 3.3081e+00, 4.1617e+00, 8.8028e+00, 5.0941e+00,\n",
      "        8.0214e+00, 4.1189e+00, 9.2540e+00, 6.0210e+00, 1.0214e+01, 6.2476e+00,\n",
      "        6.6060e+00, 3.3495e+00, 6.6210e+00, 8.5403e+00, 4.7837e+00, 6.5657e+00,\n",
      "        8.7610e+00, 1.0930e+01, 5.6443e+00, 4.2376e+00, 6.7275e+00, 7.2797e+00,\n",
      "        5.5411e+00, 3.4101e+00, 9.1764e+00, 3.3827e+00, 7.0469e+00, 9.7554e+00,\n",
      "        8.8867e+00, 5.8164e+00, 4.6305e+00, 3.2593e+00, 6.9429e+00, 7.8459e+00,\n",
      "        5.7315e+00, 3.7180e+00, 6.6571e+00, 7.0325e+00, 5.4102e+00, 7.7311e+00,\n",
      "        9.2592e+00, 7.9585e+00, 5.7901e+00, 4.9911e+00, 8.0818e+00, 3.9442e+00,\n",
      "        5.6843e+00, 8.1992e+00, 5.4445e+00, 9.1855e+00, 7.3715e+00, 9.6595e+00,\n",
      "        8.2389e+00, 6.1789e+00, 5.3306e+00, 3.1707e+00, 6.6046e+00, 4.1405e+00,\n",
      "        6.1913e+00, 9.8724e+00, 1.1903e+01, 7.4566e+00, 3.2879e+00, 6.6584e+00,\n",
      "        7.2274e+00, 7.7887e+00, 6.3385e+00, 3.9408e+00, 7.7398e+00, 8.2514e+00,\n",
      "        3.1091e+00, 4.6117e+00, 4.3439e+00, 5.4314e+00, 1.0196e+01, 3.1085e+00,\n",
      "        8.2253e+00, 8.9730e+00, 5.5733e+00, 7.3355e+00, 3.9841e+00, 4.3511e+00,\n",
      "        9.4545e+00, 8.9525e+00, 7.9818e+00, 5.5268e+00, 3.3277e+00, 6.8544e+00,\n",
      "        3.4204e+00, 4.7237e+00, 6.6715e+00, 4.1715e+00, 1.0536e+01, 3.8278e+00,\n",
      "        3.0783e+00, 8.4159e+00, 5.0820e+00, 3.6295e+00, 3.9721e+00, 4.2813e+00,\n",
      "        5.5505e+00, 6.5014e+00, 5.1746e+00, 4.0295e+00, 7.1305e+00, 3.4740e+00,\n",
      "        9.3149e+00, 5.5529e+00, 7.5499e+00, 9.9039e+00, 1.0492e+01, 7.0586e+00,\n",
      "        8.3753e+00, 5.6708e+00, 5.7051e+00, 3.6620e+00, 3.4946e+00, 7.0924e+00,\n",
      "        3.4594e+00, 3.4254e+00, 6.1138e+00, 6.2502e+00, 7.4222e+00, 6.7098e+00,\n",
      "        6.5851e+00, 5.4311e+00, 4.9711e+00, 5.8090e+00, 9.7436e+00, 4.5645e+00,\n",
      "        9.0597e+00, 6.2629e+00, 8.6934e+00, 5.3439e+00, 6.6585e+00, 6.2897e+00,\n",
      "        3.9618e+00, 8.2322e+00, 3.7826e+00, 7.6410e+00, 7.1041e+00, 3.1472e+00,\n",
      "        1.0193e+01, 6.9154e+00, 5.1198e+00, 9.6668e+00, 7.7261e+00, 1.0099e+01,\n",
      "        3.5088e+00, 3.2995e+00, 4.2222e+00, 8.1879e+00, 6.9679e+00, 4.1124e+00,\n",
      "        8.0338e+00, 7.2612e+00, 5.4664e+00, 3.6382e+00, 1.1596e+01, 3.2388e+00,\n",
      "        6.8149e+00, 4.9996e+00, 3.9202e+00, 8.6017e+00, 8.0561e+00, 7.5113e+00,\n",
      "        5.8668e+00, 5.3181e+00, 6.5807e+00, 7.3360e+00, 7.6761e+00, 5.0264e+00,\n",
      "        7.5148e+00, 4.1214e+00, 4.8010e+00, 3.3535e+00, 6.7379e+00, 6.5749e+00,\n",
      "        9.3369e+00, 7.5056e+00, 3.9662e+00, 7.5930e+00, 8.5468e+00, 6.6547e+00,\n",
      "        4.1656e+00, 3.5718e+00, 6.6771e+00, 6.2141e+00, 6.7554e+00, 4.2915e+00,\n",
      "        4.3730e+00, 4.7732e+00, 3.6596e+00, 5.1667e+00, 3.7722e+00, 5.9924e+00,\n",
      "        6.6696e+00, 1.0077e+01, 7.3898e+00, 1.0620e+01, 5.1769e+00, 6.4129e+00,\n",
      "        6.6174e+00, 4.5682e+00, 6.8032e+00, 3.7621e+00, 4.1933e+00, 6.2957e+00,\n",
      "        6.3181e+00, 3.5080e+00, 7.1979e+00, 9.2227e+00, 1.0598e+01, 7.1854e+00,\n",
      "        7.6132e+00, 5.6203e+00, 3.9545e+00, 3.4678e+00, 8.3148e+00, 6.6055e+00,\n",
      "        5.7044e+00, 6.5530e+00, 4.2763e+00, 4.5564e+00, 8.1213e+00, 3.7306e+00,\n",
      "        7.6306e+00, 6.2797e+00, 3.1790e+00, 4.1180e+00, 8.9480e+00, 9.6137e+00,\n",
      "        8.8492e+00, 4.9181e+00, 8.4994e+00, 4.0183e+00, 2.9590e+00, 9.1080e+00,\n",
      "        7.7125e+00, 6.9215e+00, 4.3087e+00, 6.6301e+00, 4.1398e+00, 4.4333e+00,\n",
      "        5.4009e+00, 4.8327e+00, 7.2381e+00, 9.7532e+00, 6.6051e+00, 9.4689e+00,\n",
      "        8.9048e+00, 4.8537e+00, 3.8479e+00, 3.4448e+00, 6.1351e+00, 6.9675e+00,\n",
      "        4.0607e+00, 9.0515e+00, 6.8805e+00, 3.9059e+00, 7.9803e+00, 8.4326e+00,\n",
      "        4.2576e+00, 9.6461e+00, 3.8228e+00, 5.9161e+00, 4.3125e+00, 8.7515e+00,\n",
      "        6.7558e+00, 4.4441e+00, 7.7946e+00, 7.2377e+00, 5.2940e+00, 5.9425e+00,\n",
      "        8.2093e+00, 8.8801e+00, 5.3729e+00, 4.5821e+00, 6.3753e+00, 4.8333e+00,\n",
      "        3.4730e+00, 7.6036e+00, 3.1603e+00, 6.7631e+00, 8.3287e+00, 5.2993e+00,\n",
      "        4.3582e+00, 6.0527e+00, 6.3237e+00, 3.5270e+00, 3.8721e+00, 6.8188e+00,\n",
      "        8.4933e+00, 9.1868e+00, 9.9125e+00, 9.6358e+00, 4.9809e+00, 7.0806e+00,\n",
      "        4.6030e+00, 7.5390e+00, 3.9722e+00, 8.2720e+00, 7.4056e+00, 4.9248e+00,\n",
      "        7.9225e+00, 7.1746e+00, 5.7956e+00, 5.6589e+00, 4.7550e+00, 5.0150e+00,\n",
      "        4.2270e+00, 5.1273e+00, 6.7738e+00, 4.3100e+00, 3.7132e+00, 5.5645e+00,\n",
      "        6.4610e+00, 6.1236e+00, 5.0087e+00, 4.2809e+00, 6.6285e+00, 4.3374e+00,\n",
      "        8.3437e+00, 4.5377e+00, 1.0937e+01, 5.5934e+00, 6.6276e+00, 6.7316e+00,\n",
      "        6.0331e+00, 3.5179e+00, 4.8322e+00, 8.9519e+00, 7.6807e+00, 4.6090e+00,\n",
      "        7.2687e+00, 4.6926e+00, 3.5030e+00, 3.6694e+00, 4.4121e+00, 8.7641e+00,\n",
      "        4.1147e+00, 7.2446e+00, 6.9879e+00, 7.9971e+00, 8.1946e+00, 8.4622e+00,\n",
      "        8.7818e+00, 3.2322e+00, 6.2307e+00, 9.7983e+00, 6.3199e+00, 7.8564e+00,\n",
      "        4.1819e+00, 8.3454e+00, 5.5920e+00, 6.9589e+00, 8.8104e+00, 6.6126e+00,\n",
      "        6.9771e+00, 3.9985e+00, 6.6719e+00, 8.5807e+00, 8.3777e+00, 4.3859e+00,\n",
      "        3.4562e+00, 7.3605e+00, 6.5123e+00, 8.0937e+00, 3.4849e+00, 5.4233e+00,\n",
      "        6.5565e+00, 6.7040e+00, 3.0468e+00, 9.3260e+00, 5.7090e+00, 6.2299e+00,\n",
      "        7.2641e+00, 8.8330e+00, 6.6351e+00, 1.0536e+01, 6.3033e+00, 6.6124e+00,\n",
      "        7.8870e+00, 5.9390e+00, 5.5359e+00, 6.0763e+00, 3.7156e+00, 7.2448e+00,\n",
      "        3.4011e+00, 3.0382e+00, 6.1433e+00, 4.2324e+00, 3.6620e+00, 8.8876e+00,\n",
      "        4.9342e+00, 3.8828e+00, 9.5364e+00, 5.0030e+00, 3.6228e+00, 3.4539e+00,\n",
      "        8.4862e+00, 1.1764e+01, 5.7633e+00, 6.7112e+00, 6.6938e+00, 3.8852e+00,\n",
      "        8.2156e+00, 1.1442e+01, 3.6966e+00, 6.5671e+00, 9.1061e+00, 9.9237e+00,\n",
      "        6.8176e+00, 3.6183e+00, 6.8239e+00, 7.0038e+00, 2.9041e+00, 3.3114e+00,\n",
      "        1.0519e+01, 7.9886e+00, 6.4125e+00, 4.7667e+00, 5.0001e+00, 8.5394e+00,\n",
      "        7.0942e+00, 4.7757e+00, 1.0487e+01, 7.7159e+00, 6.6101e+00, 6.2488e+00,\n",
      "        8.4627e+00, 9.6524e+00, 6.0289e+00, 3.4751e+00, 6.9749e+00, 6.2346e+00,\n",
      "        1.2663e+01, 3.9103e+00, 7.7273e+00, 6.1698e+00])\n",
      "torch.Size([20000])\n",
      "torch.Size([4803, 910])\n",
      "tensor([1.0000e+01, 2.0612e+05, 7.8009e+00, 3.7240e+00, 6.3249e+00, 5.1240e+00,\n",
      "        4.5632e+00, 3.4379e+00, 6.9096e+00, 6.5689e+00, 5.0217e+00, 6.7563e+00,\n",
      "        5.6691e+00, 5.6659e+00, 8.4679e+00, 6.4551e+00, 3.2712e+00, 4.1205e+00,\n",
      "        6.2173e+00, 8.7078e+00, 8.1299e+00, 7.8890e+00, 8.4005e+00, 3.6599e+00,\n",
      "        9.4834e+00, 4.4335e+00, 4.8298e+00, 6.0747e+00, 6.3031e+00, 2.7472e+00,\n",
      "        6.6321e+00, 6.1678e+00, 3.8487e+00, 4.5912e+00, 8.4895e+00, 7.8759e+00,\n",
      "        3.3507e+00, 5.3877e+00, 7.3334e+00, 5.3274e+00, 7.7410e+00, 6.3260e+00,\n",
      "        7.4494e+00, 7.1535e+00, 7.6918e+00, 6.0934e+00, 7.1334e+00, 8.7939e+00,\n",
      "        8.6024e+00, 9.2792e+00, 8.1910e+00, 4.6708e+00, 5.1932e+00, 2.8254e+00,\n",
      "        4.7235e+00, 7.4260e+00, 6.2113e+00, 8.8296e+00, 5.8215e+00, 8.3595e+00,\n",
      "        8.3757e+00, 8.7658e+00, 4.5260e+00, 5.8730e+00, 4.6855e+00, 9.0200e+00,\n",
      "        3.3144e+00, 5.9196e+00, 5.4307e+00, 3.2591e+00, 6.7867e+00, 4.8180e+00,\n",
      "        5.1602e+00, 7.9481e+00, 5.9165e+00, 3.4731e+00, 4.1421e+00, 8.6205e+00,\n",
      "        5.1499e+00, 5.5405e+00, 3.3878e+00, 9.5085e+00, 6.4242e+00, 6.9933e+00,\n",
      "        3.1255e+00, 7.7767e+00, 4.7066e+00, 6.0572e+00, 7.2762e+00, 8.3661e+00,\n",
      "        4.3762e+00, 9.9737e+00, 9.9742e+00, 6.1779e+00, 6.4201e+00, 6.1817e+00,\n",
      "        5.0143e+00, 5.0942e+00, 5.3305e+00, 6.6589e+00, 5.1706e+00, 7.7564e+00,\n",
      "        3.2613e+00, 7.2941e+00, 4.3645e+00, 4.4709e+00, 7.4454e+00, 6.7203e+00,\n",
      "        3.3760e+00, 3.1099e+00, 4.1277e+00, 9.3790e+00, 9.2048e+00, 5.2737e+00,\n",
      "        4.3173e+00, 4.4473e+00, 6.5434e+00, 2.6640e+00, 8.6981e+00, 3.4893e+00,\n",
      "        7.4455e+00, 6.7293e+00, 3.1520e+00, 3.0604e+00, 9.1342e+00, 4.0014e+00,\n",
      "        4.4306e+00, 9.0742e+00, 8.2818e+00, 2.9562e+00, 4.9606e+00, 3.5175e+00,\n",
      "        8.8809e+00, 8.5991e+00, 8.3274e+00, 7.8068e+00, 6.5790e+00, 7.3735e+00,\n",
      "        6.1163e+00, 3.8292e+00, 8.5754e+00, 1.0168e+01, 3.0492e+00, 2.9248e+00,\n",
      "        8.3591e+00, 9.9236e+00, 7.5502e+00, 9.6090e+00, 3.4143e+00, 4.0050e+00,\n",
      "        1.2414e+01, 1.0650e+01, 7.9152e+00, 4.9462e+00, 7.8795e+00, 6.9918e+00,\n",
      "        7.1379e+00, 3.5450e+00, 5.7742e+00, 7.7251e+00, 3.3402e+00, 1.1473e+01,\n",
      "        7.1699e+00, 9.2413e+00, 7.4799e+00, 8.5001e+00, 4.2536e+00, 7.2524e+00,\n",
      "        4.2310e+00, 6.5540e+00, 3.7857e+00, 5.5025e+00, 8.4231e+00, 9.9447e+00,\n",
      "        3.3456e+00, 8.9274e+00, 1.0031e+01, 3.0759e+00, 9.4045e+00, 4.5084e+00,\n",
      "        4.5364e+00, 5.7961e+00, 9.8656e+00, 4.4939e+00, 8.0455e+00, 6.1519e+00,\n",
      "        4.0535e+00, 4.6625e+00, 8.2121e+00, 8.1151e+00, 5.1818e+00, 5.1381e+00,\n",
      "        3.1766e+00, 5.4309e+00, 1.0135e+01, 5.9766e+00, 8.1056e+00, 8.5687e+00,\n",
      "        5.8695e+00, 7.1038e+00, 7.6071e+00, 5.9889e+00, 7.3915e+00, 5.8034e+00,\n",
      "        8.4723e+00, 3.4284e+00, 7.9742e+00, 5.1605e+00, 7.7074e+00, 6.1427e+00,\n",
      "        5.3127e+00, 4.5849e+00, 7.4087e+00, 5.3649e+00, 7.4666e+00, 4.7867e+00,\n",
      "        9.3433e+00, 9.2357e+00, 4.1313e+00, 1.0701e+01, 4.8156e+00, 6.7085e+00,\n",
      "        3.6782e+00, 5.9073e+00, 6.2012e+00, 8.4294e+00, 4.8909e+00, 7.7243e+00,\n",
      "        4.6288e+00, 4.3086e+00, 3.7285e+00, 6.2819e+00, 8.5632e+00, 5.5545e+00,\n",
      "        4.6561e+00, 5.6161e+00, 3.7751e+00, 4.9640e+00, 7.2335e+00, 9.7481e+00,\n",
      "        5.2133e+00, 7.6015e+00, 8.6895e+00, 1.0113e+01, 6.0616e+00, 1.0018e+01,\n",
      "        4.1844e+00, 6.1055e+00, 8.6274e+00, 8.1236e+00, 4.7989e+00, 4.8268e+00,\n",
      "        3.9244e+00, 1.0487e+01, 8.1472e+00, 4.7222e+00, 5.4460e+00, 4.9714e+00,\n",
      "        7.9876e+00, 8.1681e+00, 7.1519e+00, 3.7090e+00, 6.5660e+00, 3.7652e+00,\n",
      "        5.2398e+00, 6.2852e+00, 5.5966e+00, 5.2405e+00, 8.1811e+00, 4.8230e+00,\n",
      "        3.9760e+00, 9.1819e+00, 6.8444e+00, 8.8278e+00, 4.6352e+00, 6.5241e+00,\n",
      "        4.3096e+00, 6.9998e+00, 5.4018e+00, 7.9002e+00, 7.9539e+00, 3.3278e+00,\n",
      "        4.5453e+00, 1.0769e+01, 6.2151e+00, 7.3360e+00, 5.8120e+00, 4.4893e+00,\n",
      "        7.2518e+00, 4.9242e+00, 6.9274e+00, 8.1527e+00, 6.4609e+00, 4.7944e+00,\n",
      "        2.9849e+00, 3.0822e+00, 5.9765e+00, 4.8508e+00, 8.0498e+00, 6.5124e+00,\n",
      "        5.1241e+00, 3.0443e+00, 3.4390e+00, 5.3484e+00, 6.2889e+00, 7.7185e+00,\n",
      "        4.7104e+00, 5.3860e+00, 5.6423e+00, 4.9156e+00, 8.5797e+00, 6.7357e+00,\n",
      "        6.0145e+00, 5.6018e+00, 8.4670e+00, 6.6227e+00, 6.9781e+00, 6.1687e+00,\n",
      "        1.2809e+01, 7.2808e+00, 4.5601e+00, 5.5845e+00, 6.4422e+00, 3.3062e+00,\n",
      "        7.9501e+00, 5.1862e+00, 3.8763e+00, 8.2615e+00, 3.5065e+00, 6.0301e+00,\n",
      "        4.1902e+00, 5.9942e+00, 4.5103e+00, 3.0136e+00, 5.9972e+00, 7.4001e+00,\n",
      "        7.1182e+00, 8.0512e+00, 7.6982e+00, 6.9870e+00, 6.7490e+00, 7.1420e+00,\n",
      "        6.5708e+00, 7.9691e+00, 6.8515e+00, 4.6919e+00, 6.5948e+00, 7.3749e+00,\n",
      "        3.1147e+00, 5.9227e+00, 6.4327e+00, 9.5803e+00, 8.4809e+00, 5.8472e+00,\n",
      "        7.1840e+00, 3.8311e+00, 8.1204e+00, 1.1070e+01, 6.7159e+00, 6.8480e+00,\n",
      "        8.6108e+00, 3.7807e+00, 5.9479e+00, 1.0716e+01, 7.7463e+00, 7.3647e+00,\n",
      "        7.1699e+00, 5.0901e+00, 7.3462e+00, 3.6515e+00, 2.6981e+00, 8.5194e+00,\n",
      "        8.5338e+00, 9.3580e+00, 5.7563e+00, 8.2532e+00, 5.1822e+00, 3.9531e+00,\n",
      "        7.4608e+00, 5.2114e+00, 4.1042e+00, 7.1538e+00, 3.5819e+00, 4.5922e+00,\n",
      "        7.5304e+00, 3.4401e+00, 4.8100e+00, 9.1442e+00, 7.3562e+00, 4.1055e+00,\n",
      "        5.9407e+00, 4.9256e+00, 5.9262e+00, 6.4814e+00, 8.1930e+00, 1.2555e+01,\n",
      "        6.2727e+00, 8.7331e+00, 6.0577e+00, 8.9714e+00, 3.0298e+00, 4.2991e+00,\n",
      "        7.3774e+00, 8.5198e+00, 9.2705e+00, 7.1550e+00, 6.4425e+00, 8.1602e+00,\n",
      "        8.9625e+00, 8.9699e+00, 4.8284e+00, 4.1480e+00, 4.3143e+00, 3.5711e+00,\n",
      "        3.4317e+00, 9.0950e+00, 6.3797e+00, 5.4769e+00, 6.3877e+00, 6.7138e+00,\n",
      "        2.9796e+00, 7.1618e+00, 4.4977e+00, 7.7691e+00, 8.8016e+00, 5.9256e+00,\n",
      "        4.3305e+00, 6.5208e+00, 5.6867e+00, 4.8247e+00, 8.7826e+00, 8.0651e+00,\n",
      "        4.0145e+00, 9.3454e+00, 9.9253e+00, 3.1867e+00, 7.8471e+00, 5.4575e+00,\n",
      "        3.2178e+00, 6.8359e+00, 3.8305e+00, 5.8617e+00, 9.1641e+00, 9.8017e+00,\n",
      "        7.2524e+00, 7.5814e+00, 5.5272e+00, 7.5340e+00, 3.6817e+00, 6.4985e+00,\n",
      "        8.4665e+00, 5.4764e+00, 9.8095e+00, 5.9687e+00, 8.0795e+00, 8.2259e+00,\n",
      "        9.5932e+00, 7.4445e+00, 8.3135e+00, 3.2932e+00, 6.1059e+00, 7.5045e+00,\n",
      "        7.6704e+00, 7.3116e+00, 8.7702e+00, 7.3899e+00, 7.6613e+00, 9.7583e+00,\n",
      "        5.8726e+00, 6.6820e+00, 4.5469e+00, 4.4852e+00, 6.3762e+00, 5.7404e+00,\n",
      "        6.6003e+00, 5.5928e+00, 9.9241e+00, 5.0926e+00, 9.0157e+00, 7.4659e+00,\n",
      "        6.7366e+00, 6.3793e+00, 6.2417e+00, 4.6374e+00, 4.2573e+00, 6.9024e+00,\n",
      "        3.0659e+00, 9.2217e+00, 5.6415e+00, 4.1003e+00, 5.4484e+00, 7.5226e+00,\n",
      "        4.7545e+00, 8.7748e+00, 1.0328e+01, 4.3714e+00, 6.1525e+00, 8.2400e+00,\n",
      "        1.0420e+01, 6.1039e+00, 4.0138e+00, 8.4163e+00, 4.6010e+00, 7.0095e+00,\n",
      "        6.5408e+00, 3.9444e+00, 7.1921e+00, 7.5777e+00, 6.2940e+00, 7.7810e+00,\n",
      "        8.7631e+00, 6.8361e+00, 7.2712e+00, 7.1758e+00, 6.8422e+00, 3.7613e+00,\n",
      "        5.5692e+00, 8.6907e+00, 6.1351e+00, 8.4505e+00, 7.6351e+00, 9.4397e+00,\n",
      "        8.2600e+00, 6.4145e+00, 4.0844e+00, 3.2131e+00, 5.6228e+00, 4.5147e+00,\n",
      "        6.1080e+00, 1.0779e+01, 1.2602e+01, 4.6258e+00, 4.2324e+00, 6.4366e+00,\n",
      "        1.0077e+01, 9.2455e+00, 5.5774e+00, 4.0526e+00, 1.1828e+01, 6.7847e+00,\n",
      "        3.1313e+00, 6.6030e+00, 4.7902e+00, 6.0905e+00, 9.5345e+00, 3.5753e+00,\n",
      "        5.1459e+00, 7.7452e+00, 2.9090e+00, 5.8965e+00, 4.0222e+00, 3.7832e+00,\n",
      "        8.5781e+00, 1.0289e+01, 7.3142e+00, 6.4136e+00, 4.0884e+00, 7.7214e+00,\n",
      "        3.5145e+00, 5.0063e+00, 6.7397e+00, 5.6813e+00, 1.0601e+01, 8.6917e+00,\n",
      "        3.3927e+00, 7.1275e+00, 5.4586e+00, 4.2672e+00, 5.0083e+00, 4.6023e+00,\n",
      "        5.9967e+00, 6.8016e+00, 1.0626e+01, 4.1259e+00, 8.3958e+00, 3.5359e+00,\n",
      "        6.9504e+00, 8.0755e+00, 6.9281e+00, 8.3999e+00, 1.1002e+01, 7.3028e+00,\n",
      "        8.0577e+00, 5.5686e+00, 5.2025e+00, 3.9419e+00, 4.9242e+00, 7.3654e+00,\n",
      "        3.5384e+00, 3.5968e+00, 6.7945e+00, 5.8149e+00, 6.2255e+00, 5.9361e+00,\n",
      "        7.4398e+00, 7.7893e+00, 4.3783e+00, 5.0475e+00, 8.3584e+00, 4.5676e+00,\n",
      "        7.5176e+00, 3.6968e+00, 6.4129e+00, 5.6437e+00, 4.9334e+00, 9.0062e+00,\n",
      "        4.3517e+00, 8.0373e+00, 3.2798e+00, 3.3804e+00, 6.3989e+00, 4.0362e+00,\n",
      "        2.9499e+00, 6.8016e+00, 7.8761e+00, 7.7945e+00, 7.4169e+00, 8.8195e+00,\n",
      "        3.8383e+00, 3.2530e+00, 4.3921e+00, 8.5322e+00, 6.3236e+00, 3.6026e+00,\n",
      "        7.4595e+00, 5.6187e+00, 5.5307e+00, 3.7973e+00, 1.1329e+01, 4.0294e+00,\n",
      "        8.6561e+00, 7.9966e+00, 4.3640e+00, 7.6920e+00, 5.5098e+00, 8.0078e+00,\n",
      "        5.4144e+00, 5.7082e+00, 7.9979e+00, 7.3363e+00, 8.6475e+00, 5.0638e+00,\n",
      "        7.0478e+00, 4.0275e+00, 4.8653e+00, 4.3229e+00, 6.8212e+00, 3.6236e+00,\n",
      "        8.8069e+00, 6.2007e+00, 4.1492e+00, 7.7962e+00, 6.3304e+00, 7.9210e+00,\n",
      "        4.6274e+00, 3.7896e+00, 3.9081e+00, 5.4755e+00, 5.2198e+00, 3.4238e+00,\n",
      "        3.0021e+00, 5.2229e+00, 4.1073e+00, 5.1299e+00, 3.6923e+00, 5.4300e+00,\n",
      "        3.8069e+00, 7.9398e+00, 6.0380e+00, 1.0289e+01, 5.3053e+00, 5.1526e+00,\n",
      "        7.1941e+00, 4.3794e+00, 7.8569e+00, 4.7395e+00, 4.4693e+00, 8.2827e+00,\n",
      "        4.1860e+00, 3.6635e+00, 6.9619e+00, 8.8312e+00, 9.3977e+00, 4.4791e+00,\n",
      "        7.7738e+00, 4.7302e+00, 3.8846e+00, 3.4562e+00, 8.1774e+00, 8.4291e+00,\n",
      "        5.1453e+00, 3.2376e+00, 3.9506e+00, 5.9088e+00, 7.7994e+00, 4.5533e+00,\n",
      "        6.4407e+00, 3.7782e+00, 3.4583e+00, 5.4410e+00, 7.6706e+00, 9.1475e+00,\n",
      "        5.2521e+00, 4.9128e+00, 7.4838e+00, 3.4282e+00, 3.1306e+00, 9.2369e+00,\n",
      "        6.4222e+00, 6.4082e+00, 3.7306e+00, 8.1643e+00, 3.4905e+00, 4.6034e+00,\n",
      "        5.1364e+00, 3.0948e+00, 7.4398e+00, 9.2708e+00, 6.3760e+00, 9.3684e+00,\n",
      "        9.5882e+00, 4.4222e+00, 4.3584e+00, 4.0196e+00, 6.1301e+00, 6.4101e+00,\n",
      "        4.0953e+00, 9.4590e+00, 6.5843e+00, 4.4878e+00, 7.4940e+00, 7.8135e+00,\n",
      "        4.6054e+00, 9.5297e+00, 3.5717e+00, 5.5984e+00, 6.2287e+00, 3.8483e+00,\n",
      "        8.0074e+00, 6.5140e+00, 8.9473e+00, 6.9609e+00, 5.2560e+00, 6.2657e+00,\n",
      "        7.2773e+00, 1.0631e+01, 4.1071e+00, 3.0136e+00, 6.9195e+00, 6.2177e+00,\n",
      "        9.8317e+00, 8.6893e+00, 6.8916e+00, 7.3164e+00, 6.1229e+00, 4.2465e+00,\n",
      "        3.7476e+00, 5.9882e+00, 6.3554e+00, 3.4898e+00, 4.5076e+00, 9.7125e+00,\n",
      "        6.9453e+00, 7.3992e+00, 8.0923e+00, 8.2878e+00, 3.9605e+00, 7.0763e+00,\n",
      "        4.4184e+00, 9.1895e+00, 6.7347e+00, 8.0593e+00, 7.7333e+00, 4.8508e+00,\n",
      "        6.7659e+00, 5.3325e+00, 6.1139e+00, 5.7224e+00, 5.5891e+00, 7.9100e+00,\n",
      "        4.0054e+00, 7.6015e+00, 5.3563e+00, 3.9630e+00, 3.8441e+00, 5.6634e+00,\n",
      "        5.8812e+00, 6.4176e+00, 3.9290e+00, 4.7082e+00, 7.3301e+00, 4.2413e+00,\n",
      "        6.3378e+00, 3.6728e+00, 1.0002e+01, 6.0057e+00, 3.6497e+00, 7.2595e+00,\n",
      "        7.1271e+00, 3.8942e+00, 5.0902e+00, 8.2031e+00, 7.2538e+00, 4.5045e+00,\n",
      "        9.4012e+00, 5.0520e+00, 3.5241e+00, 4.0542e+00, 4.1224e+00, 6.7533e+00,\n",
      "        7.3016e+00, 6.8163e+00, 3.9306e+00, 7.9762e+00, 6.9420e+00, 7.3766e+00,\n",
      "        9.0998e+00, 3.3860e+00, 6.4105e+00, 9.0185e+00, 6.4955e+00, 7.3421e+00,\n",
      "        4.4762e+00, 7.7250e+00, 6.4793e+00, 5.9602e+00, 7.2460e+00, 4.0595e+00,\n",
      "        6.4430e+00, 4.5108e+00, 6.6240e+00, 7.8520e+00, 9.0445e+00, 4.3708e+00,\n",
      "        5.5103e+00, 6.5905e+00, 5.9591e+00, 7.1985e+00, 3.5282e+00, 8.8702e+00,\n",
      "        5.1255e+00, 3.4643e+00, 3.0517e+00, 6.1805e+00, 6.2617e+00, 6.9306e+00,\n",
      "        7.2009e+00, 6.9070e+00, 6.5036e+00, 9.5585e+00, 6.7101e+00, 1.0429e+01,\n",
      "        6.3493e+00, 1.0614e+01, 5.1683e+00, 7.2251e+00, 5.0565e+00, 7.0219e+00,\n",
      "        3.6582e+00, 3.4787e+00, 7.6105e+00, 4.5473e+00, 3.3884e+00, 9.1297e+00,\n",
      "        5.1025e+00, 4.3709e+00, 9.3493e+00, 5.9419e+00, 4.2156e+00, 3.7389e+00,\n",
      "        7.9702e+00, 9.4012e+00, 7.8495e+00, 6.4125e+00, 7.4713e+00, 4.0284e+00,\n",
      "        7.0833e+00, 8.4729e+00, 3.8786e+00, 6.9943e+00, 8.1596e+00, 8.1142e+00,\n",
      "        7.6824e+00, 4.9672e+00, 7.1598e+00, 8.7082e+00, 2.9380e+00, 3.3577e+00,\n",
      "        1.1094e+01, 7.7726e+00, 6.6283e+00, 7.1819e+00, 6.1022e+00, 8.7592e+00,\n",
      "        5.2177e+00, 5.2246e+00, 7.4683e+00, 7.3587e+00, 6.9664e+00, 6.7725e+00,\n",
      "        6.8392e+00, 9.0341e+00, 6.3119e+00, 4.0426e+00, 9.5279e+00, 6.7461e+00,\n",
      "        1.1998e+01, 4.6102e+00, 7.9238e+00, 5.9679e+00])\n",
      "torch.Size([4803])\n"
     ]
    }
   ],
   "source": [
    "for i, (X_test_batch, y_test_batch) in enumerate(test_loader):  \n",
    "    print(X_test_batch.size())\n",
    "    print(X_test_batch[i])\n",
    "    print(y_test_batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84803\n",
      "tensor(1.0450e+10)\n",
      "Mean absolute difference of the network on the 84803 test values: 123222.046875\n"
     ]
    }
   ],
   "source": [
    "from numpy import vstack\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# ---------------------------------\n",
    "# Test the model\n",
    "# ---------------------------------\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    inputs, predictions, actuals = list(), list(), list()\n",
    "    for X, y in test_loader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        outputs = model(X)\n",
    "        predicted = outputs.data\n",
    "\n",
    "        y_preds  = outputs.detach().numpy()\n",
    "        y_actual = y.detach().numpy() \n",
    "        y_actual = y_actual.reshape((len(y_actual), 1))\n",
    "\n",
    "        assert y_preds.shape == y_actual.shape\n",
    "        \n",
    "        inputs.append(X.detach().numpy())\n",
    "        predictions.append(y_preds)\n",
    "        actuals.append(y_actual)\n",
    "\n",
    "        total += y.size(0)\n",
    "        # print(f\"predicted y : {predicted}    actual y : {y}\\n\\n\\n\\n\")\n",
    "        # print(f\"actual    y : {y}\\n\\n\")\n",
    "        correct += np.abs(predicted - y).sum()\n",
    "\n",
    "    print(total)\n",
    "    print(correct)\n",
    "    print(f\"Mean absolute difference of the network on the {len(test_loader.dataset.indices)} test values: {correct / total:2.6f}\")\n",
    "\n",
    "    inputs, predictions, actuals = vstack(inputs), vstack(predictions), vstack(actuals)\n",
    "    # calculate mse\n",
    "    mse = mean_squared_error(actuals, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(15, 5)});\n",
    "fig, ax = plt.subplots(1, 2);\n",
    "\n",
    "sns.histplot(np.abs(actuals-predictions), bins=100, legend=False, ax=ax[0]);\n",
    "ax[0].set_title('With Outliers');\n",
    "ax[0].set_xlabel('Abs(actual - prediction)');\n",
    "sns.boxplot(np.abs(actuals-predictions), showfliers=False, ax=ax[1]);\n",
    "ax[1].set_title('Without Outliers');\n",
    "ax[1].set_xlabel('Abs(actual - prediction)');\n",
    "plt.suptitle(f'Distribution of the absolute difference between predictions and actual LN(IC50) values.\\nMSE = {mse:2.2f}');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110.26407"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20000, 910])\n",
      "torch.Size([20000, 910])\n",
      "torch.Size([20000, 910])\n",
      "torch.Size([20000, 910])\n",
      "torch.Size([4803, 910])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for X, y in test_loader:\n",
    "    print(X.shape)\n",
    "    c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    424015.000000\n",
       "mean          2.194876\n",
       "std           2.688787\n",
       "min         -10.579334\n",
       "25%           0.833991\n",
       "50%           2.615133\n",
       "75%           4.111724\n",
       "max          12.359056\n",
       "Name: LN_IC50, dtype: float64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_nonnan.LN_IC50.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            input_size  = 910\n",
      "            hidden_size = 64\n",
      "            num_classes = 1\n",
      "        \n",
      "SimpleNN_GeneExpr(\n",
      "  (fc1): Linear(in_features=910, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Model structure: SimpleNN_GeneExpr(\n",
      "  (fc1): Linear(in_features=910, out_features=64, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "Layer: fc1.weight | Size: torch.Size([64, 910]) | Values : tensor([[ 0.0031, -0.0272,  0.0308,  ..., -0.0007, -0.0200,  0.0291],\n",
      "        [ 0.0129, -0.0039, -0.0077,  ..., -0.0066, -0.0268,  0.0217]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc1.bias | Size: torch.Size([64]) | Values : tensor([-0.0063,  0.0170], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc2.weight | Size: torch.Size([1, 64]) | Values : tensor([[-0.1118, -0.0632, -0.0409, -0.0645, -0.0033,  0.0511, -0.0150,  0.0214,\n",
      "         -0.1160,  0.0529,  0.0969, -0.1158, -0.1116, -0.0962,  0.1024,  0.0488,\n",
      "         -0.1139, -0.1227,  0.0618,  0.0701,  0.0309,  0.0626,  0.0922, -0.0660,\n",
      "          0.0247,  0.1061,  0.0109, -0.0806, -0.0197,  0.0894, -0.0646, -0.1006,\n",
      "          0.0749, -0.1185,  0.0140,  0.0624,  0.0757, -0.0718,  0.0584, -0.0183,\n",
      "          0.0144,  0.0421,  0.0105, -0.1144, -0.0700,  0.1185,  0.0574,  0.1109,\n",
      "          0.0498,  0.0847, -0.0535, -0.0890, -0.0427,  0.0084, -0.1044, -0.0109,\n",
      "         -0.1012,  0.0138,  0.0625,  0.0934,  0.0506, -0.0069, -0.1076, -0.1036]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: fc2.bias | Size: torch.Size([1]) | Values : tensor([0.0545], grad_fn=<SliceBackward0>) \n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "tensor([[129.3490],\n",
      "        [209.9591],\n",
      "        [  4.5756],\n",
      "        ...,\n",
      "        [621.0994],\n",
      "        [ 54.3161],\n",
      "        [922.4257]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([25000])) that is different to the input size (torch.Size([25000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-8.8719e+01],\n",
      "        [-9.6946e+02],\n",
      "        [-5.3419e+01],\n",
      "        ...,\n",
      "        [-4.1394e+05],\n",
      "        [-3.6030e+03],\n",
      "        [-6.9712e+01]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ -36.7172],\n",
      "        [ -20.7834],\n",
      "        [-304.9717],\n",
      "        ...,\n",
      "        [ -25.3333],\n",
      "        [ -21.4341],\n",
      "        [-491.2570]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 14.4568],\n",
      "        [392.7724],\n",
      "        [ 78.6831],\n",
      "        ...,\n",
      "        [ 65.4693],\n",
      "        [  5.7414],\n",
      "        [ 56.5482]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.3643e+05],\n",
      "        [4.7884e+04],\n",
      "        [8.0635e+02],\n",
      "        ...,\n",
      "        [1.8662e+01],\n",
      "        [1.9338e+02],\n",
      "        [1.2746e+03]], grad_fn=<AddmmBackward0>)\n",
      "Epoch [1/10], Step [5/14], Loss: 1421595136.0000\n",
      "tensor([[ 71.0781],\n",
      "        [175.5704],\n",
      "        [652.1816],\n",
      "        ...,\n",
      "        [ 29.0352],\n",
      "        [227.7199],\n",
      "        [151.1791]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[1.3534e+01],\n",
      "        [3.8229e+00],\n",
      "        [3.1521e+02],\n",
      "        ...,\n",
      "        [5.8455e+04],\n",
      "        [1.6432e+01],\n",
      "        [4.3748e+00]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/cwoest/Documents/Academics/Data_Science_UP/master_thesis/material/GNN-material/06_create_base_dataset.ipynb Cell 45'\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cwoest/Documents/Academics/Data_Science_UP/master_thesis/material/GNN-material/06_create_base_dataset.ipynb#ch0000077?line=69'>70</a>\u001b[0m \u001b[39m# Backward and optimize\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cwoest/Documents/Academics/Data_Science_UP/master_thesis/material/GNN-material/06_create_base_dataset.ipynb#ch0000077?line=70'>71</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/cwoest/Documents/Academics/Data_Science_UP/master_thesis/material/GNN-material/06_create_base_dataset.ipynb#ch0000077?line=71'>72</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cwoest/Documents/Academics/Data_Science_UP/master_thesis/material/GNN-material/06_create_base_dataset.ipynb#ch0000077?line=72'>73</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cwoest/Documents/Academics/Data_Science_UP/master_thesis/material/GNN-material/06_create_base_dataset.ipynb#ch0000077?line=74'>75</a>\u001b[0m \u001b[39mif\u001b[39;00m (i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m \u001b[39m5\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39m# was % 100 before\u001b[39;00m\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/_tensor.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/_tensor.py?line=354'>355</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/_tensor.py?line=355'>356</a>\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/_tensor.py?line=356'>357</a>\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/_tensor.py?line=360'>361</a>\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/_tensor.py?line=361'>362</a>\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/_tensor.py?line=362'>363</a>\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/autograd/__init__.py?line=167'>168</a>\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/autograd/__init__.py?line=169'>170</a>\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/autograd/__init__.py?line=170'>171</a>\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/autograd/__init__.py?line=171'>172</a>\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/autograd/__init__.py?line=172'>173</a>\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/autograd/__init__.py?line=173'>174</a>\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    <a href='file:///users/cwoest/Applications/anaconda3/envs/master-thesis-log/lib/python3.10/site-packages/torch/autograd/__init__.py?line=174'>175</a>\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ---------------------------------\n",
    "# Build the Neural Netowrk\n",
    "# ---------------------------------\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class SimpleNN_GeneExpr(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(SimpleNN_GeneExpr, self).__init__()\n",
    "        print(f\"\"\"\n",
    "            input_size  = {input_size}\n",
    "            hidden_size = {hidden_size}\n",
    "            num_classes = {num_classes}\n",
    "        \"\"\")\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)   # module that applies a linear transformation on the input using its stored weights and biases.\n",
    "        self.relu = nn.ReLU()                           # Non-linear activations are what create the complex mappings between the model’s inputs and outputs. No introduce nonlinearity, helping neural networks learn a wide variety of phenomena.\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleNN_GeneExpr(input_size, hidden_size=64, num_classes=num_classes).to(device)\n",
    "print(model)\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")\n",
    "print(100*\"-\")\n",
    "\n",
    "# Loss and optimizer\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# ---------------------------------\n",
    "# Train the model\n",
    "# ---------------------------------\n",
    "loss_values = []\n",
    "total_step = len(train_loader)\n",
    "it = iter(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (X_batch, y_batch) in enumerate(train_loader):  \n",
    "        #images = images.reshape(-1, 28*28).to(device)\n",
    "        #labels = labels.to(device)\n",
    "        # if i > 3: break\n",
    "\n",
    "        # Move tensors to the configured device\n",
    "        X = X_batch.to(device)  # All feature values\n",
    "        y = y_batch.to(device)  # The ln(IC50) values\n",
    "        # print(20*\"+\")\n",
    "        # print(f\"i={i}\")\n",
    "        # print(X.size())\n",
    "        # print(y.size())\n",
    "        # print(X)\n",
    "        # print(y)\n",
    "        assert not torch.isnan(X).any(), \"X has NaN in it\"\n",
    "        assert not torch.isnan(X).any(), \"y has NaN in it\"\n",
    "        # print(\"outputs...\")\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        print(outputs)\n",
    "        loss = loss_func(outputs, y_batch)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 5 == 0: # was % 100 before\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))    \n",
    "\n",
    "    loss_values.append(running_loss / len(gene_expr_dataset))                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c78b81650a0bd32063743affb6953ff71b1a0dba806fbca9e2db842718495748"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('master-thesis-log')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
