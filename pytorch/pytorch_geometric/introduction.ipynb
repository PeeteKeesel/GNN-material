{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Following the [Introduction By Example](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html) provided by pytorch-geometric.\n",
    "\n",
    "__Other Tutorial Resources:__\n",
    "- [pypi torch-geometric](https://pypi.org/project/torch-geometric/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /users/cwoest/Applications/anaconda3\n",
      "gdsctools_env            /users/cwoest/Applications/anaconda3/envs/gdsctools_env\n",
      "master-thesis-log     *  /users/cwoest/Applications/anaconda3/envs/master-thesis-log\n",
      "r-env                    /users/cwoest/Applications/anaconda3/envs/r-env\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conda 4.10.3\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Python version:   3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:45:10) [Clang 12.0.1 ]\n",
      "    PyTorch version:  1.11.0\n",
      "    Device:           cpu\n",
      "    CUDA available:   False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"\"\"\n",
    "    Python version:   {sys.version}\n",
    "    PyTorch version:  {torch.__version__}\n",
    "    Device:           {device}\n",
    "    CUDA available:   {torch.cuda.is_available()}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Handling of Graphs\n",
    "\n",
    "| Attributes | Shape | Description |\n",
    "| ---------- | ----- | ----------- |\n",
    "| `data.x`          | `[num_nodes, num_node_features]` | Node feature matrix |\n",
    "| `data.edge_index` | `[2, num_edges]` | Graph connectivity in COO format |\n",
    "| `data.edge_attr`  | `[num_edges, num:edge_features]` | Edge feature matrix |\n",
    "| `data.y`          | arbitrary | Traget to train against. <br> - Node-level targets `[num_nodes, *]` <br> - Graph-level targets `[1, *]` |\n",
    "| `data.pos`        | `[num_nodes, num_dimensions]` | Node position matrix |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3, 1], edge_index=[2, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "########################\n",
    "# Definition of a graph.\n",
    "########################\n",
    "\n",
    "# Define edges.\n",
    "edge_index = torch.tensor(\n",
    "    [[0, 1, 1, 2],  # from\n",
    "     [1, 0, 2, 1]], # to\n",
    "     dtype=torch.long\n",
    ")\n",
    "\n",
    "# Define nodes.\n",
    "x = torch.tensor(\n",
    "    [[-1], [0], [1]], dtype=torch.float\n",
    ")\n",
    "\n",
    "# Define single graph in PyG.\n",
    "data = Data(\n",
    "    x=x,\n",
    "    edge_index=edge_index\n",
    ")\n",
    "\n",
    "# Shapes of the edge and feature matrices.\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `[3, 1]` means the graph has 3 nodes and 1 feature per node\n",
    "- `[2, 4]` means the graph has 4 edges and if undirected this means 2 edges\n",
    "\n",
    "The above graph `data` has the following adjacency matrix:\n",
    "```\n",
    "    0  1  0\n",
    "    1  0  1 \n",
    "    0  1  0\n",
    "```\n",
    "\n",
    "__Remember__: \n",
    "\n",
    "- `x` has shape `[num_nodes, num_node_features]`\n",
    "- `edge_index` has shape `[2, num_edges]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3, 1], edge_index=[2, 4])\n"
     ]
    }
   ],
   "source": [
    "# Define as list of index tuples.\n",
    "edge_index = torch.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [1, 2],\n",
    "                           [2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "# Use contiguous if the tensor which defines the source and target nodes of all edges\n",
    "# should be defined as a list of index tuples.\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous())\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'edge_index']\n",
      "tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "False\n",
      "\n",
      "Graph parameters\n",
      "---------------------\n",
      "   # of nodes       : 3\n",
      "   # of edges       : 4\n",
      "   # nodes features : 1\n",
      "   # edge features  : 0\n",
      "   \n",
      "   has_isolated_nodes : False\n",
      "   has_self_loops     : False\n",
      "   is_directed        : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Utility functions.\n",
    "####################\n",
    "\n",
    "# Keys of the graph.\n",
    "print(data.keys)\n",
    "\n",
    "# Access value of a key.\n",
    "print(data['x']) # or print(data.x)\n",
    "\n",
    "# Check if a key is contained in the graph.\n",
    "print('edge_attr' in data)\n",
    "\n",
    "# Size parameters of the graph.\n",
    "print(f\"\"\"\\nGraph parameters\n",
    "---------------------\n",
    "   # of nodes       : {data.num_nodes}\n",
    "   # of edges       : {data.num_edges}\n",
    "   # nodes features : {data.num_node_features}\n",
    "   # edge features  : {data.num_edge_features}\n",
    "   \n",
    "   has_isolated_nodes : {data.has_isolated_nodes()}\n",
    "   has_self_loops     : {data.has_self_loops()}\n",
    "   is_directed        : {data.is_directed()}\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Benchmark Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [TUDatasets](https://chrsmrrs.github.io/datasets/docs/datasets/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "    dataset             : ENZYMES(600)\n",
      "    len(dataset)        : 600\n",
      "    num_classes         : 6\n",
      "\n",
      "    Node:\n",
      "    -----\n",
      "    num_node_features   : 3\n",
      "    num_node_attributes : 0\n",
      "    num_node_labels     : 3  \n",
      "\n",
      "    Edge:\n",
      "    -----      \n",
      "    num_edge_features   : 0\n",
      "    num_edge_attributes : 0\n",
      "    num_edge_labels     : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "\n",
    "dataset = TUDataset(root='ENZYMES', name='ENZYMES')\n",
    "\n",
    "print(f\"\"\" \n",
    "    dataset             : {dataset}\n",
    "    len(dataset)        : {len(dataset)}\n",
    "    num_classes         : {dataset.num_classes}\n",
    "\n",
    "    Node:\n",
    "    -----\n",
    "    num_node_features   : {dataset.num_node_features}\n",
    "    num_node_attributes : {dataset.num_node_attributes}\n",
    "    num_node_labels     : {dataset.num_node_labels}  \n",
    "\n",
    "    Edge:\n",
    "    -----      \n",
    "    num_edge_features   : {dataset.num_edge_features}\n",
    "    num_edge_attributes : {dataset.num_edge_attributes}\n",
    "    num_edge_labels     : {dataset.num_edge_labels}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `len(dataset)` = Number of Graphs\n",
    "- _ENZYMES_ consists of 600 graphs within 6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 90], x=[24, 3], y=[1])\n",
      "is_undirected : True\n"
     ]
    }
   ],
   "source": [
    "# Access a specific graph.\n",
    "data = dataset[3]\n",
    "print(data)\n",
    "\n",
    "print(f\"is_undirected : {data.is_undirected()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the _ENZYMES_ dataset contains\n",
    "- 24 nodes\n",
    "  - each node has 3 features\n",
    "- 90 edges (since the graph is _undirected_, this means there are 45 edges)\n",
    "- Graph is assigned to exactly one class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations : 19\n",
      "\n",
      "DataBatch(edge_index=[2, 3850], x=[993, 21], y=[32], batch=[993], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 3814], x=[984, 21], y=[32], batch=[984], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 3756], x=[1020, 21], y=[32], batch=[1020], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 4030], x=[1118, 21], y=[32], batch=[1118], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 4350], x=[1088, 21], y=[32], batch=[1088], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 4132], x=[1077, 21], y=[32], batch=[1077], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 4266], x=[1093, 21], y=[32], batch=[1093], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 3772], x=[1069, 21], y=[32], batch=[1069], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 4150], x=[1118, 21], y=[32], batch=[1118], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 3820], x=[967, 21], y=[32], batch=[967], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 3708], x=[967, 21], y=[32], batch=[967], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 4146], x=[1085, 21], y=[32], batch=[1085], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 4304], x=[1178, 21], y=[32], batch=[1178], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 3770], x=[1014, 21], y=[32], batch=[1014], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 3540], x=[903, 21], y=[32], batch=[903], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 3572], x=[934, 21], y=[32], batch=[934], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 4482], x=[1178, 21], y=[32], batch=[1178], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 3866], x=[1010, 21], y=[32], batch=[1010], ptr=[33])\n",
      "num_graphs: 32\n",
      "DataBatch(edge_index=[2, 3236], x=[784, 21], y=[24], batch=[784], ptr=[25])\n",
      "num_graphs: 24\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"Iterations : {len(loader)}\\n\")\n",
    "for batch in loader:\n",
    "    print(batch)\n",
    "    print(f\"num_graphs: {batch.num_graphs}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# num_iters_with_full_batch_size + one iteration with smaller batch size.\n",
    "18*32 + 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        i                 : 0\n",
      "        data              : DataBatch(edge_index=[2, 4030], x=[1035, 21], y=[32], batch=[1035], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 1\n",
      "        data              : DataBatch(edge_index=[2, 4318], x=[1116, 21], y=[32], batch=[1116], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 2\n",
      "        data              : DataBatch(edge_index=[2, 3726], x=[949, 21], y=[32], batch=[949], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 3\n",
      "        data              : DataBatch(edge_index=[2, 4042], x=[1157, 21], y=[32], batch=[1157], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 4\n",
      "        data              : DataBatch(edge_index=[2, 3986], x=[1041, 21], y=[32], batch=[1041], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 5\n",
      "        data              : DataBatch(edge_index=[2, 3962], x=[1011, 21], y=[32], batch=[1011], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 6\n",
      "        data              : DataBatch(edge_index=[2, 4250], x=[1061, 21], y=[32], batch=[1061], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 7\n",
      "        data              : DataBatch(edge_index=[2, 3524], x=[925, 21], y=[32], batch=[925], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 8\n",
      "        data              : DataBatch(edge_index=[2, 4240], x=[1087, 21], y=[32], batch=[1087], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 9\n",
      "        data              : DataBatch(edge_index=[2, 4026], x=[1027, 21], y=[32], batch=[1027], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 10\n",
      "        data              : DataBatch(edge_index=[2, 3900], x=[1012, 21], y=[32], batch=[1012], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 11\n",
      "        data              : DataBatch(edge_index=[2, 3712], x=[1028, 21], y=[32], batch=[1028], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 12\n",
      "        data              : DataBatch(edge_index=[2, 4198], x=[1092, 21], y=[32], batch=[1092], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 13\n",
      "        data              : DataBatch(edge_index=[2, 4450], x=[1206, 21], y=[32], batch=[1206], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 14\n",
      "        data              : DataBatch(edge_index=[2, 3466], x=[931, 21], y=[32], batch=[931], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 15\n",
      "        data              : DataBatch(edge_index=[2, 3774], x=[963, 21], y=[32], batch=[963], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 16\n",
      "        data              : DataBatch(edge_index=[2, 3830], x=[1038, 21], y=[32], batch=[1038], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 17\n",
      "        data              : DataBatch(edge_index=[2, 4406], x=[1192, 21], y=[32], batch=[1192], ptr=[33])\n",
      "        num_graphs        : 32\n",
      "        scatter_mean.size : torch.Size([32, 21])         (average node features in the node dimension)\n",
      "    \n",
      "\n",
      "        i                 : 18\n",
      "        data              : DataBatch(edge_index=[2, 2724], x=[709, 21], y=[24], batch=[709], ptr=[25])\n",
      "        num_graphs        : 24\n",
      "        scatter_mean.size : torch.Size([24, 21])         (average node features in the node dimension)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset = TUDataset(root='ENZYMES', name='ENZYMES', use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for i, data in enumerate(loader):\n",
    "    x = scatter_mean(data.x, data.batch, dim=0)\n",
    "    print(f\"\"\"\n",
    "        i                 : {i}\n",
    "        data              : {data}\n",
    "        num_graphs        : {data.num_graphs}\n",
    "        scatter_mean.size : {x.size()}         (average node features in the node dimension)\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `batch`: column vector which maps each node to its respective graph in the batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Methods on Graphs\n",
    "\n",
    "Implementation of a simple GCN layer. \n",
    "\n",
    "- [Explanation of GCNs](http://tkipf.github.io/graph-convolutional-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "# Load Cora dataset\n",
    "dataset = Planetoid(root='Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "    dataset[0] : Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "    dataset[0].is_undirected() : True\n",
      "\n",
      "actual number of edges : 5278.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\" \n",
    "    dataset[0] : {dataset[0]}\n",
    "    dataset[0].is_undirected() : {dataset[0].is_undirected()}\n",
    "\"\"\")\n",
    "\n",
    "if dataset[0].is_undirected():\n",
    "    print(f\"actual number of edges : {dataset[0].edge_index.shape[1] / 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Platenoid dataset contains\n",
    "- 2708 nodes with 1433 features each\n",
    "- 10556 edges (and since its an undirected graph there are 10556/2 = 5278 edges)\n",
    "- 2708 target node values for each node\n",
    "  - Since `y` has shape `[2708, *]` we have _node-level prediction targets_, thus a target for each node.\n",
    "- Train set contains 2708 boolean entries, which each entry specifying if the node is contained in the train set or not\n",
    "  - The same holds for val and test set\n",
    "  - Obviously, if e.g. index 15 is `True` for the val mask, it will be `False` for the train and test masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    dataset           : Cora()\n",
      "    num_node_features : 1433\n",
      "    num_edge_features : 0\n",
      "    num_classes       : 7\n",
      "    num_features      : 1433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    dataset           : {dataset}\n",
    "    num_node_features : {dataset.num_node_features}\n",
    "    num_edge_features : {dataset.num_edge_features}\n",
    "    num_classes       : {dataset.num_classes}\n",
    "    num_features      : {dataset.num_features}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of a 2-layer GCN.\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 convolutional layers\n",
    "- 1st layer : `[1433, 16]`\n",
    "- ReLU\n",
    "- Dropout\n",
    "- 2nd layer : `[16, 7]`\n",
    "- Log-Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:   1  Loss: 1.9526757002\n",
      "0.0005\n",
      "Epoch:  21  Loss: 0.2469878048\n",
      "0.0005\n",
      "Epoch:  41  Loss: 0.0600667670\n",
      "0.0005\n",
      "Epoch:  61  Loss: 0.0701837912\n",
      "0.0005\n",
      "Epoch:  81  Loss: 0.0456110276\n",
      "0.0005\n",
      "Epoch: 101  Loss: 0.0341489501\n",
      "0.0005\n",
      "Epoch: 121  Loss: 0.0428811610\n",
      "0.0005\n",
      "Epoch: 141  Loss: 0.0218738653\n",
      "0.0005\n",
      "Epoch: 161  Loss: 0.0245752838\n",
      "0.0005\n",
      "Epoch: 181  Loss: 0.0235794187\n",
      "0.0005\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "# Train model on the training nodes for 200 epochs.\n",
    "###################################################\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Set model and data to the CPU.\n",
    "model = GCN().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Set module in training mode.\n",
    "model.train()\n",
    "\n",
    "NUM_EPOCHS = 200\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Set all gradients to zero.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    out = model(data) \n",
    "\n",
    "    # Calculate negative log likelihood loss for the train data.\n",
    "    loss = F.nll_loss(\n",
    "        out[data.train_mask],\n",
    "        data.y[data.train_mask]\n",
    "    )\n",
    "\n",
    "    # Backpropagation: Compute gradients via chain rule.\n",
    "    loss.backward()\n",
    "\n",
    "    # Performs a single optimization step (parameter update).\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print training statistics.\n",
    "    running_loss = loss.item()\n",
    "    if epoch % 20 == 0:    # print every 2000 mini-batches\n",
    "        print(f'Epoch: {(epoch + 1):3d}  Loss: {running_loss:.10f}')\n",
    "        for pg in optimizer.param_groups:\n",
    "            print(pg['weight_decay'])\n",
    "        running_loss = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7960\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test nodes.\n",
    "model.eval()\n",
    "\n",
    "pred = model(data).argmax(dim=1)  # For each row, the indices of the maximal value per row.\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()  # Number of correct predictions.\n",
    "acc = int(correct) / int(data.test_mask.sum())  # How many of all test nodes were predicted correctly?\n",
    "print(f\"Accuracy : {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
